@book{2016nicomachean,
  title={Nicomachean Ethics},
  author={Aristotle and {W. D. Ross}},
  year={2016},
  isbn={978-1539025580}
}
@misc{coqhistory,
  title = {{Early History of Coq}},
  journal = {Early history of Coq - Coq 8.15.0 documentation},
  url = {https://coq.inria.fr/refman/history.html}
}
@misc{fortran2,
  title = {{FORTRAN II for the IBM 704 Data Processing System}},
  author = {{International Business Machines Corporation}},
  year = 1958,
  note = {Accessed: {2023–01-30}},
  howpublished = {\url{https://archive.org/details/bitsavers_ibm704C286_3406140/}}
}
@book{mccarthy1965lisp,
  title = {{LISP 1.5 Programmer's Manual}},
  author = {McCarthy, John and Levin, Michael I.},
  year = 1965,
  publisher = {MIT Press}
}
@inproceedings{bcSmith,
    author = {Smith, Brian Cantwell},
    title = {{Reflection and Semantics in LISP}},
    year = {1984},
    isbn = {0897911253},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/800017.800513},
    doi = {10.1145/800017.800513},
    booktitle = {Proceedings of the 11th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    pages = {23–35},
    numpages = {13},
    location = {Salt Lake City, Utah, USA},
    series = {POPL '84}
}
@article{stallman1987c,
  title = {{The C Preprocessor}},
  author = {Stallman, Richard M and Weinberg, Zachary},
  year = 1987,
  journal = {Free Software Foundation},
  pages = 16,
  url={https://web.archive.org/web/20240210213047/https://gcc.gnu.org/onlinedocs/cpp.pdf}
}

@inproceedings{hoas,
    author = {Pfenning, Frank and Elliott, Conal},
    title = {{Higher-Order Abstract Syntax}},
    year = {1988},
    isbn = {0897912691},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/53990.54010},
    doi = {10.1145/53990.54010},
    abstract = {We describe motivation, design, use, and implementation of higher-order abstract syntax as a central representation for programs, formulas, rules, and other syntactic objects in program manipulation and other formal systems where matching and substitution or unification are central operations. Higher-order abstract syntax incorporates name binding information in a uniform and language generic way. Thus it acts as a powerful link integrating diverse tools in such formal environments. We have implemented higher-order abstract syntax, a supporting matching and unification algorithm, and some clients in Common Lisp in the framework of the Ergo project at Carnegie Mellon University.},
    booktitle = {Proceedings of the ACM SIGPLAN 1988 Conference on Programming Language Design and Implementation},
    pages = {199–208},
    numpages = {10},
    location = {Atlanta, Georgia, USA},
    series = {PLDI '88}
}

@inproceedings{coquand1988inductively,
  title = {{Inductively Defined Types}},
  author = {Coquand, Thierry and Paulin, Christine},
  year = 1988,
  booktitle = {International Conference on Computer Logic},
  pages = {50--66},
  organization = {Springer},
  url={https://doi.org/10.1007/3-540-52335-9_47}
}
@article{mogensen,
  title = {{Efficient Self-Interpretation in Lambda Calculus}},
  author = {Torben Æ. Mogensen},
  year = 1992,
  journal = {Journal of Functional Programming},
  volume = 2,
  pages = {345--364}
}
@inproceedings{scott,
  title = {{Types for the Scott Numerals}},
  author = {Abadi, Martin and Cardelli, Luca and Plotkin, Gordon},
  year = 1993
}
@article{dybjer1994,
  title = {{Inductive Families}},
  author = {Dybjer, Peter},
  year = 1994,
  month = {jul},
  journal = {Form. Asp. Comput.},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  volume = 6,
  number = 4,
  pages = {440–465},
  doi = {10.1007/BF01211308},
  issn = {0934-5043},
  url = {https://doi.org/10.1007/BF01211308},
  issue_date = {Jul 1994},
  abstract = {A general formulation of inductive and recursive definitions in Martin-L\"{o}f's type theory is presented. It extends Backhouse's ‘Do-It-Yourself Type Theory’ to include inductive definitions of families of sets and definitions of functions by recursion on the way elements of such sets are generated. The formulation is in natural deduction and is intended to be a natural generalisation to type theory of Martin-L\"{o}f's theory of iterated inductive definitions in predicate logic.Formal criteria are given for correct formation and introduction rules of a new set former capturing definition by strictly positive, iterated, generalised induction. Moreover, there is an inversion principle for deriving elimination and equality rules from the formation and introduction rules. Finally, there is an alternative schematic presentation of definition by recursion.The resulting theory is a flexible and powerful language for programming and constructive mathematics. We hint at the wealth of possible applications by showing several basic examples: predicate logic, generalised induction, and a formalisation of the untyped lambda calculus.},
  numpages = 26,
  keywords = {Intuitionistic type theory, Inductive definitions, Natural deduction}
}
@inproceedings{jansson1997,
  title = {{PolyP—a Polytypic Programming Language Extension}},
  author = {Jansson, Patrik and Jeuring, Johan},
  year = 1997,
  booktitle = {Proceedings of the 24th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  location = {Paris, France},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {POPL '97},
  pages = {470–482},
  doi = {10.1145/263699.263763},
  isbn = {0897918533},
  url = {https://doi.org/10.1145/263699.263763},
  abstract = {Many functions have to be written over and over again for different datatypes, either because datatypes change during the development of programs, or because functions with similar functionality are needed on different datatypes. Examples of such functions are pretty printers, debuggers, equality functions, unifiers, pattern matchers, rewriting functions, etc. Such functions are called polytypic functions. A polytypic function is a function that is defined by induction on the structure of user-defined datatypes. This paper extends a functional language (a subset of Haskell) with a construct for writing polytypic functions. The extended language type checks definitions of polytypic functions, and infers the types of all other expressions using an extension of Jones' theories of qualified types and higher-order polymorphism. The semantics of the programs in the extended language is obtained by adding type arguments to functions in a dictionary passing style. Programs in the extended language are translated to Haskell.},
  numpages = 13
}
@book{appel1998modern,
  title = {{Modern Compiler Implementation in ML}},
  author = {Appel, Andrew W.},
  year = 1998,
  publisher = {Addison-Wesley},
  isbn={978-0521582742}
}

@inproceedings{steele1998growing,
    author = {Steele, Guy L.},
    title = {{Growing a Language}},
    year = {1998},
    isbn = {1581132867},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/346852.346922},
    doi = {10.1145/346852.346922},
    booktitle = {Addendum to the 1998 Proceedings of the Conference on Object-Oriented Programming, Systems, Languages, and Applications (Addendum)},
    pages = {0.01–A1},
    location = {Vancouver, British Columbia, Canada},
    series = {OOPSLA '98 Addendum}
}
@inproceedings{bawden1999quasiquotation,
  title = {{Quasiquotation in Lisp}},
  author = {Bawden, Alan},
  year = 1999,
  journal = {PEPM},
  pages = {4--12}
}
@book{Plato2000,
  title = {{{The Republic}}},
  author = {{Plato}},
  year = 2000,
  month = sep,
  publisher = {Cambridge University Press},
  address = {Cambridge, England},
  series = {{{Cambridge Texts in the History of Political Thought}}},
  editor = {Ferrari, G R F},
  language = {en},
  isbn={978-0521484435}
}

@inproceedings{taha2000metaml,
    author = {Taha, Walid and Sheard, Tim},
    title = {{Multi-Stage Programming with Explicit Annotations}},
    year = {1997},
    isbn = {0897919173},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/258993.259019},
    doi = {10.1145/258993.259019},
    abstract = {We introduce MetaML, a statically-typed multi-stage programming language extending Nielson and Nielson's two stage notation to an arbitrary number of stages. MetaML extends previous work by introducing four distinct staging annotations which generalize those published previously [25, 12, 7, 6]We give a static semantics in which type checking is done once and for all before the first stage, and a dynamic semantics which introduces a new concept of cross-stage persistence, which requires that variables available in any stage are also available in all future stages.We illustrate that staging is a manual form of binding time analysis. We explain why, even in the presence of automatic binding time analysis, explicit annotations are useful, especially for programs with more than two stages.A thesis of this paper is that multi-stage languages are useful as programming languages in their own right, and should support features that make it possible for programmers to write staged computations without significantly changing their normal programming style. To illustrate this we provide a simple three stage example, and an extended two-stage example elaborating a number of practical issues.},
    booktitle = {Proceedings of the 1997 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation},
    pages = {203–217},
    numpages = {15},
    location = {Amsterdam, The Netherlands},
    series = {PEPM '97}
}

      

@inproceedings{delahaye2000tactic,
  title = {{A Tactic Language for the System Coq}},
  author = {Delahaye, David},
  year = 2000,
  booktitle = {Logic for Programming and Automated Reasoning: 7th International Conference, LPAR 2000 Reunion Island, France, November 6--10, 2000 Proceedings 7},
  pages = {85--95},
  organization = {Springer},
  url={https://doi.org/10.1007/3-540-44404-1_7}
}
@article{sheard2001,
  title = {{Accomplishments and Research Challenges in Meta-Programming}},
  author = {Sheard, Tim},
  year = 2001,
  journal = {SAIG},
  volume = 2196,
  number = 3,
  pages = {2--44},
  url={https://doi.org/10.1007/3-540-44806-3_2}
}
@article{sheard2002template,
  title = {{Template Meta-Programming for Haskell}},
  author = {Sheard, Tim and Jones, Simon Peyton},
  year = 2002,
  month = {Dec},
  journal = {SIGPLAN Not.},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = 37,
  number = 12,
  pages = {60–75},
  doi = {10.1145/636517.636528},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/636517.636528},
  issue_date = {December 2002},
  abstract = {We propose a new extension to the purely functional programming language Haskell that supports compile-time meta-programming. The purpose of the system is to support the algorithmic construction of programs at compile-time.The ability to generate code at compile time allows the programmer to implement such features as polytypic programs, macro-like expansion, user directed optimization (such as inlining), and the generation of supporting data structures and functions from existing data structures and functions.Our design is being implemented in the Glasgow Haskell Compiler, ghc.},
  numpages = 16,
  keywords = {templates, Meta programming}
}
@inproceedings{syb,
author = {L\"{a}mmel, Ralf and Jones, Simon Peyton},
title = {{Scrap Your Boilerplate - A Practical Design Pattern for Generic Programming}},
year = {2003},
isbn = {1581136498},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/604174.604179},
doi = {10.1145/604174.604179},
abstract = {We describe a design pattern for writing programs that traverse data structures built from rich mutually-recursive data types. Such programs often have a great deal of "boilerplate" code that simply walks the structure, hiding a small amount of "real" code that constitutes the reason for the traversal.Our technique allows most of this boilerplate to be written once and for all, or even generated mechanically, leaving the programmer free to concentrate on the important part of the algorithm. These generic programs are much more adaptive when faced with data structure evolution because they contain many fewer lines of type-specific code.Our approach is simple to understand, reasonably efficient, and it handles all the data types found in conventional functional programming languages. It makes essential use of rank-2 polymorphism, an extension found in some implementations of Haskell. Further it relies on a simple type-safe cast operator.},
booktitle = {Proceedings of the 2003 ACM SIGPLAN International Workshop on Types in Languages Design and Implementation},
pages = {26–37},
numpages = {12},
keywords = {generic programming, rank-2 types, traversal, type cast},
location = {New Orleans, Louisiana, USA},
series = {TLDI '03}
}
@techreport{cheney2003first,
  title = {{First-Class Phantom Types}},
  author = {Cheney, James and Hinze, Ralf},
  year = 2003,
  institution = {Cornell University},
  url={https://hdl.handle.net/1813/5614}
}
@article{hinze2003chapter,
  title = {{Generic Haskell: Applications}},
  author = {Hinze, Ralf and Jeuring, Johan},
  year = 2003,
  journal = {Generic Programming: Advanced Lectures},
  publisher = {Springer},
  pages = {57--96},
  url={https://doi.org/10.1007/978-3-540-45191-4_2}
}
@incollection{taha2004,
  title = {{A Gentle Introduction to Multi-Stage Programming}},
  author = {Taha, Walid},
  year = 2004,
  booktitle = {Domain-Specific Program Generation},
  publisher = {Springer, Berlin, Heidelberg},
  address = {Berlin, Heidelberg},
  pages = {30--50},
  url={https://doi.org/10.1007/978-3-540-25935-0_3}
}
@inproceedings{coutts2004,
  title = {{Partial Evaluation for Domain-Specific Embedded Languages in a Higher Order Typed Language}},
  author = {Duncan Coutts},
  year = 2004,
  url={https://web.archive.org/web/20170830054633/http://www.cs.ox.ac.uk/people/duncan.coutts/papers/transfer_dissertation.pdf}
}
@inproceedings{sybc,
  title = {Scrap Your Boilerplate with Class: Extensible Generic Functions},
  author = {L{\"a}mmel, Ralf and {Peyton Jones}, Simon},
  year = 2005,
  journal = {ICFP}
}
@phdthesis{barzilayphd,
  title = {{Implementing Reflection in Nuprl}},
  author = {Barzilay, Eli},
  year = 2006,
  school = {Cornell University}
}
@incollection{reflectionMasses,
  title = {{Reflection for the Masses}},
  author = {Herzeel, Charlotte and Costanza, Pascal and D'Hondt, Theo},
  year = 2008,
  booktitle = {Self-Sustaining Systems},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  pages = {87--122},
  editor = {Hirschfeld, Robert and Rose, Kim},
  numpages = 36
}
@phdthesis{matthews2008meaning,
  title = {{The Meaning of Multilanguage Programs}},
  author = {Matthews, Jacob Burton},
  year = 2008,
  school = {{The University of Chicago}},
  url={https://web.archive.org/web/20240331001311/https://plt.cs.northwestern.edu/matthews-phd.pdf}
}
@inproceedings{sozeau2008first,
  title={{First-Class Type Classes}},
  author={Sozeau, Matthieu and Oury, Nicolas},
  booktitle={International Conference on Theorem Proving in Higher Order Logics},
  pages={278--293},
  year={2008},
  organization={Springer},
  url = {https://doi.org/10.1007/978-3-540-71067-7_23},
}
@article{stump2009directly,
  title = {{Directly Reflective Meta-Programming}},
  author = {Stump, Aaron},
  year = 2009,
  journal = {Higher-Order and Symbolic Computation},
  publisher = {Springer},
  volume = 22,
  number = 2,
  pages = {115--144}
}
@article{leroy2009,
  title = {{Formal Verification of a Realistic Compiler}},
  author = {Leroy, Xavier},
  year = 2009,
  month = {jul},
  journal = {Commun. ACM},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = 52,
  number = 7,
  pages = {107–115},
  doi = {10.1145/1538788.1538814},
  issn = {0001-0782},
  url = {https://doi.org/10.1145/1538788.1538814},
  issue_date = {July 2009},
  abstract = {This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
  numpages = 9
}
@article{magalhaes2010generic,
  title = {{A Generic Deriving Mechanism for Haskell}},
  author = {Magalh{\~a}es, Jos{\'e} Pedro and Dijkstra, Atze and Jeuring, Johan and L{\"o}h, Andres},
  year = 2010,
  journal = {ACM Sigplan Notices},
  publisher = {ACM},
  volume = 45,
  number = 11,
  pages = {37--48}
}

@inproceedings{chapman2010gentle,
    author = {Chapman, James and Dagand, Pierre-\'{E}variste and McBride, Conor and Morris, Peter},
    title = {{The Gentle Art of Levitation}},
    year = {2010},
    isbn = {9781605587943},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1863543.1863547},
    doi = {10.1145/1863543.1863547},
    abstract = {We present a closed dependent type theory whose inductive types are given not by a scheme for generative declarations, but by encoding in a universe. Each inductive datatype arises by interpreting its description - a first-class value in a datatype of descriptions. Moreover, the latter itself has a description. Datatype-generic programming thus becomes ordinary programming. We show some of the resulting generic operations and deploy them in particular, useful ways on the datatype of datatype descriptions itself. Simulations in existing systems suggest that this apparently self-supporting setup is achievable without paradox or infinite regress.},
    booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    pages = {3–14},
    numpages = {12},
    keywords = {data structure, metaprogramming, monads, proof assistants, type systems},
    location = {Baltimore, Maryland, USA},
    series = {ICFP '10}
}
@book{tanaka2010semiotics,
  title = {{Semiotics of Programming}},
  author = {Tanaka-Ishii, Kumiko},
  year = 2010,
  publisher = {Cambridge University Press},
  isbn={978-0521736275}
}
@book{cpdt,
  title = {{Certified Programming with Dependent Types}},
  author = {Chlipala, Adam},
  year = 2011,
  publisher = {MIT Press}
}

@inproceedings{rompf2012,
author = {Rompf, Tiark and Odersky, Martin},
title = {{Lightweight Modular Staging: A Pragmatic Approach to Runtime Code Generation and Compiled DSLs}},
year = {2010},
isbn = {9781450301541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1868294.1868314},
doi = {10.1145/1868294.1868314},
abstract = {Software engineering demands generality and abstraction, performance demands specialization and concretization. Generative programming can provide both, but the effort required to develop high-quality program generators likely offsets their benefits, even if a multi-stage programming language is used.We present lightweight modular staging, a library-based multi-stage programming approach that breaks with the tradition of syntactic quasi-quotation and instead uses only types to distinguish between binding times. Through extensive use of component technology, lightweight modular staging makes an optimizing compiler framework available at the library level, allowing programmers to tightly integrate domain-specific abstractions and optimizations into the generation process.We argue that lightweight modular staging enables a form of language virtualization, i.e. allows to go from a pure-library embedded language to one that is practically equivalent to a stand-alone implementation with only modest effort.},
booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
pages = {127–136},
numpages = {10},
keywords = {code generation, domain-specific languages, language virtualization, multi-stage programming},
location = {Eindhoven, The Netherlands},
series = {GPCE '10}
}
@inproceedings{devriese2013typed,
  title = {{Typed Syntactic Meta-Programming}},
  author = {Devriese, Dominique and Piessens, Frank},
  year = 2013,
  journal = {ICFP}
}
@article{idris,
  title = {{Idris, A General-Purpose Dependently Typed Programming Language: Design and Implementation}},
  author = {Brady, Edwin},
  year = 2013,
  journal = {Journal of Functional Programming},
  publisher = {Cambridge University Press},
  volume = 23,
  number = 5,
  pages = {552--593}
}
@inproceedings{koopman2014church,
  title = {{Church Encoding of Data Types Considered Harmful for Implementations}},
  author = {Koopman, Pieter and Plasmeijer, Rinus and Jansen, Jan Martin},
  year = 2014,
  journal = {IFL}
}
@inproceedings{idrisQuotation,
  title = {{Type-Directed Elaboration of Quasiquotations: A High-Level Syntax for Low-Level Reflection}},
  author = {Christiansen, David Raymond},
  year = 2014,
  journal = {IFL}
}
@article{10.1145/2578855.2535841,
  title = {{CakeML: A Verified Implementation of ML}},
  author = {Kumar, Ramana and Myreen, Magnus O. and Norrish, Michael and Owens, Scott},
  year = 2014,
  month = {jan},
  journal = {SIGPLAN Not.},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = 49,
  number = 1,
  pages = {179–191},
  doi = {10.1145/2578855.2535841},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/2578855.2535841},
  issue_date = {January 2014},
  abstract = {We have developed and mechanically verified an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our verification effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitrary-precision arithmetic, and compiler bootstrapping.Our contributions are twofold. The first is simply in building a system that is end-to-end verified, demonstrating that each piece of such a verification effort can in practice be composed with the others, and ensuring that none of the pieces rely on any over-simplifying assumptions. The second is developing novel approaches to some of the more challenging aspects of the verification. In particular, our formally verified compiler can bootstrap itself: we apply the verified compiler to itself to produce a verified machine-code implementation of the compiler. Additionally, our compiler proof handles diverging input programs with a lightweight approach based on logical timeout exceptions. The entire development was carried out in the HOL4 theorem prover.},
  numpages = 13,
  keywords = {verified type checking, ML, compiler bootstrapping, machine code verification, verified garbage collection., verified parsing, read-eval-print loop, compiler verification}
}
@inproceedings{kumar2014,
  title = {{CakeML: A Verified Implementation of ML}},
  author = {Kumar, Ramana and Myreen, Magnus O. and Norrish, Michael and Owens, Scott},
  year = 2014,
  booktitle = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  location = {San Diego, California, USA},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {POPL '14},
  pages = {179–191},
  doi = {10.1145/2535838.2535841},
  isbn = 9781450325448,
  url = {https://doi.org/10.1145/2535838.2535841},
  abstract = {We have developed and mechanically verified an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our verification effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitrary-precision arithmetic, and compiler bootstrapping.Our contributions are twofold. The first is simply in building a system that is end-to-end verified, demonstrating that each piece of such a verification effort can in practice be composed with the others, and ensuring that none of the pieces rely on any over-simplifying assumptions. The second is developing novel approaches to some of the more challenging aspects of the verification. In particular, our formally verified compiler can bootstrap itself: we apply the verified compiler to itself to produce a verified machine-code implementation of the compiler. Additionally, our compiler proof handles diverging input programs with a lightweight approach based on logical timeout exceptions. The entire development was carried out in the HOL4 theorem prover.},
  numpages = 13,
  keywords = {verified type checking, verified parsing, read-eval-print loop, ML, verified garbage collection., compiler bootstrapping, compiler verification, machine code verification}
}
@inproceedings{brownU,
  title = {{Self-Representation in Girard's System U}},
  author = {Brown, Matt and Palsberg, Jens},
  year = 2015,
  journal = {POPL}
}
@inproceedings{ahmed2015verified,
  title = {{Verified Compilers for a Multi-Language World}},
  author = {Ahmed, Amal},
  year = 2015,
  booktitle = {1st Summit on Advances in Programming Languages (SNAPL 2015)},
  organization = {Schloss Dagstuhl-Leibniz-Zentrum f\"ur Informatik},
  url={https://web.archive.org/web/20240401021538/https://www.khoury.northeastern.edu/home/amal/papers/verifcomp.pdf}
}
@inproceedings{brownBreaking,
  title = {{Breaking Through the Normalization Barrier: A Self-Interpreter for F-omega}},
  author = {Brown, Matt and Palsberg, Jens},
  year = 2016,
  journal = {POPL}
}
@misc{bergerSlides,
  title = {{Foundations of Meta-Programming}},
  author = {Berger, Martin},
  year = 2016,
  note = {Accessed: {2022–03-22}},
  howpublished = {\url{https://www.cl.cam.ac.uk/events/metaprog/2016/metaprogramming-martin-berger.pdf}}
}
@inproceedings{hgmp,
  title = {{Modelling Homogeneous Generative Meta-Programming}},
  author = {Berger, Martin and Tratt, Laurence and Urban, Christian},
  year = 2017,
  journal = {ECOOP},
  url={https://doi.org/10.48550/arXiv.1602.06568},
  doi={10.48550/arXiv.1602.06568}
}
@inproceedings{brownIntensional,
  title = {{Typed Self-evaluation via Intensional Type Functions}},
  author = {Brown, Matt and Palsberg, Jens},
  year = 2017,
  journal = {POPL}
}
@inproceedings{certicoq,
  title = {{CertiCoq: A Verified Compiler for Coq}},
  author = {Anand, Abhishek and Appel, Andrew W. and Morrisett, Greg and Paraskevopoulou, Zoe and Pollack, Randy and {Savary Bélanger}, Olivier and Sozeau, Matthieu and Weaver, Matthew},
  year = 2017,
  booktitle = {the 3rd International Workshop on Coq for Programming Languages (CoqPL)},
  url={https://web.archive.org/web/20221117172213/https://www.cs.princeton.edu/~appel/papers/certicoq-coqpl.pdf}
}
@inproceedings{kell2017some,
author = {Kell, Stephen},
title = {{Some Were Meant for C: The Endurance of an Unmanageable Language}},
year = {2017},
isbn = {9781450355308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3133850.3133867},
doi = {10.1145/3133850.3133867},
abstract = {The C language leads a double life: as an application programming language of yesteryear, perpetuated by circumstance; and as a systems programming language which remains a weapon of choice decades after its creation. This essay is a C programmer's reaction to the call to abandon ship. It questions several aspects commonly held to define the experience of using C; these include unsafety, undefined behaviour, and the motivation of performance. It argues all these are in fact inessential; rather, it traces C's ultimate strength to a communicative design which cannot be understood within the usual conception of "a programming language", but can be seen as the antithesis of so-called "managed" languages. This communicativity is understood as facilitating the essential aspect of system-building: creating parts which interact with other remote parts---being "alongside" not "within", and of "alien" origin.},
booktitle = {Proceedings of the 2017 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {229–245},
numpages = {17},
keywords = {managed languages, safety, systems programming, undefined behavior, virtual machine},
location = {Vancouver, BC, Canada},
series = {Onward! 2017}
}
@article{patterson2017,
  title = {{FunTAL: Reasonably Mixing a Functional Language with Assembly}},
  author = {Patterson, Daniel and Perconti, Jamie and Dimoulas, Christos and Ahmed, Amal},
  year = 2017,
  month = {jun},
  journal = {SIGPLAN Not.},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = 52,
  number = 6,
  pages = {495–509},
  doi = {10.1145/3140587.3062347},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/3140587.3062347},
  issue_date = {June 2017},
  abstract = {We present FunTAL, the first multi-language system to formalize safe interoperability between a high-level functional language and low-level assembly code while supporting compositional reasoning about the mix. A central challenge in developing such a multi-language is bridging the gap between assembly, which is staged into jumps to continuations, and high-level code, where subterms return a result. We present a compositional stack-based typed assembly language that supports components, comprised of one or more basic blocks, that may be embedded in high-level contexts. We also present a logical relation for FunTAL that supports reasoning about equivalence of high-level components and their assembly replacements, mixed-language programs with callbacks between languages, and assembly components comprised of different numbers of basic blocks.},
  numpages = 15,
  keywords = {inline assembly, typed assembly language, logical relations, contextual equivalence, multi-language semantics}
}
@inproceedings{templatecoq,
  title = {{Towards Certified Meta-Programming with Typed Template-Coq}},
  author = {Anand, Abhishek and Boulier, Simon and Cohen, Cyril and Sozeau, Matthieu and Tabareau, Nicolas},
  year = 2018,
  booktitle = {International Conference on Interactive Theorem Proving},
  pages = {20--39},
  organization = {Springer},
  url={https://doi.org/10.1007/978-3-319-94821-8_2}
}

@inproceedings{stucki2018,
author = {Stucki, Nicolas and Biboudis, Aggelos and Odersky, Martin},
title = {{A Practical Unification Of Multi-Stage Programming and Macros}},
year = {2018},
isbn = {9781450360456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3278122.3278139},
doi = {10.1145/3278122.3278139},
abstract = {Program generation is indispensable. We propose a novel unification of two existing metaprogramming techniques: multi-stage programming and hygienic generative macros. The former supports runtime code generation and execution in a type-safe manner while the latter offers compile-time code generation.  In this work we draw upon a long line of research on metaprogramming, starting with Lisp, MetaML and MetaOCaml. We provide direct support for quotes, splices and top-level splices, all regulated uniformly by a level-counting Phase Consistency Principle. Our design enables the construction and combination of code values for both expressions and types. Moreover, code generation can happen either at runtime \`{a} la MetaML or at compile time, in a macro fashion, \`{a} la MacroML.  We provide an implementation of our design in Scala and we present two case studies. The first implements the Hidden Markov Model, Shonan Challenge for HPC. The second implements the staged streaming library Strymonas.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {14–27},
numpages = {14},
keywords = {Scala, Multi-stage programming, Macros},
location = {Boston, MA, USA},
series = {GPCE 2018}
}
@inproceedings{kawata2019dependently,
  title={{A Dependently Typed Multi-Stage Calculus}},
  author={Kawata, Akira and Igarashi, Atsushi},
  booktitle={Asian Symposium on Programming Languages and Systems},
  pages={53--72},
  year={2019},
  organization={Springer},
  url={https://doi.org/10.1007/978-3-030-34175-6_4}
}
@article{patterson2019,
  title = {{The Next 700 Compiler Correctness Theorems (Functional Pearl)}},
  author = {Patterson, Daniel and Ahmed, Amal},
  year = 2019,
  month = {jul},
  journal = {Proc. ACM Program. Lang.},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = 3,
  number = {ICFP},
  doi = {10.1145/3341689},
  url = {https://doi.org/10.1145/3341689},
  issue_date = {August 2019},
  abstract = {Compiler correctness is an old problem, with results stretching back beyond the last half-century. Founding the field, John McCarthy and James Painter set out to build a "completely trustworthy compiler". And yet, until quite recently, even despite truly impressive verification efforts, the theorems being proved were only about the compilation of whole programs, a theoretically quite appealing but practically unrealistic simplification. For a compiler correctness theorem to assure complete trust, the theorem must reflect the reality of how the compiler will be used. There has been much recent work on more realistic "compositional" compiler correctness aimed at proving correct compilation of components while supporting linking with components compiled from different languages using different compilers. However, the variety of theorems, stated in remarkably different ways, raises questions about what researchers even mean by a "compiler is correct." In this pearl, we develop a new framework with which to understand compiler correctness theorems in the presence of linking, and apply it to understanding and comparing this diversity of results. In doing so, not only are we better able to assess their relative strengths and weaknesses, but gain insight into what we as a community should expect from compiler correctness theorems of the future.},
  articleno = 85,
  numpages = 29,
  keywords = {verification, compilers}
}
@phdthesis{belanger2019verified,
  title = {{Verified Extraction for Coq}},
  author = {{Savary B{\'e}langer}, Olivier},
  year = 2019,
  school = {Princeton University},
  url={https://web.archive.org/web/20220521073059/https://www.cs.princeton.edu/techreports/2019/011.pdf}
}
@article{belanger2019certified,
  title = {{Certified Code Generation from CPS to C}},
  author = {{Savary B{\'e}langer}, Olivier and Weaver, Matthew Z and Appel, Andrew W.},
  year = 2019,
  url={https://web.archive.org/web/20230322153846/https://www.cs.princeton.edu/~appel/papers/CPStoC.pdf}
}
@article{sozeau2020metacoq,
  title = {{The MetaCoq Project}},
  author = {Sozeau, Matthieu and Anand, Abhishek and Boulier, Simon and Cohen, Cyril and Forster, Yannick and Kunze, Fabian and Malecha, Gregory and Tabareau, Nicolas and Winterhalter, Th{\'e}o},
  year = 2020,
  journal = {Journal of Automated Reasoning},
  publisher = {Springer},
  volume = 64,
  number = 5,
  pages = {947--999},
  url={https://doi.org/10.1007/s10817-019-09540-0}
}
@phdthesis{paraskevopoulou2020verified,
  title = {{Verified Optimizations for Functional Languages}},
  author = {Paraskevopoulou, Zoe},
  year = 2020,
  school = {Princeton University},
  url={https://web.archive.org/web/20230706171148/https://www.cs.princeton.edu/techreports/2020/006.pdf}
}

@article{paraskevopoulou2021compositional,
author = {Paraskevopoulou, Zoe and Li, John M. and Appel, Andrew W.},
title = {{Compositional Optimizations for CertiCoq}},
year = {2021},
issue_date = {August 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {ICFP},
url = {https://doi.org/10.1145/3473591},
doi = {10.1145/3473591},
abstract = {Compositional compiler verification is a difficult problem that focuses on separate compilation of program components with possibly different verified compilers. Logical relations are widely used in proving correctness of program transformations in higher-order languages; however, they do not scale to compositional verification of multi-pass compilers due to their lack of transitivity. The only known technique to apply to compositional verification of multi-pass compilers for higher-order languages is parametric inter-language simulations (PILS), which is however significantly more complicated than traditional proof techniques for compiler correctness. In this paper, we present a novel verification framework for lightweight compositional compiler correctness. We demonstrate that by imposing the additional restriction that program components are compiled by pipelines that go through the same sequence of intermediate representations, logical relation proofs can be transitively composed in order to derive an end-to-end compositional specification for multi-pass compiler pipelines. Unlike traditional logical-relation frameworks, our framework supports divergence preservation—even when transformations reduce the number of program steps. We achieve this by parameterizing our logical relations with a pair of relational invariants. We apply this technique to verify a multi-pass, optimizing middle-end pipeline for CertiCoq, a compiler from Gallina (Coq’s specification language) to C. The pipeline optimizes and closure-converts an untyped functional intermediate language (ANF or CPS) to a subset of that language without nested functions, which can be easily code-generated to low-level languages. Notably, our pipeline performs more complex closure-allocation optimizations than the state of the art in verified compilation. Using our novel verification framework, we prove an end-to-end theorem for our pipeline that covers both termination and divergence and applies to whole-program and separate compilation, even when different modules are compiled with different optimizations. Our results are mechanized in the Coq proof assistant.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {86},
numpages = {30},
keywords = {separate compilation, logical relations, lambda lifting, compositional compiler correctness, compilation by transformation, closure conversion, A-normal form}
}

@mastersthesis{vassilev2019,
  author={Vassilev, Katja},
  title={{Specification of the Dead Parameter Elimination Optimization of the CertiCoq Compiler}},
  year={2019},
  url={http://arks.princeton.edu/ark:/88435/dsp015m60qv74k},
  school={Princeton University},
  type = "Senior thesis"
}

@article{xie2022staging,
author = {Xie, Ningning and Pickering, Matthew and L\"{o}h, Andres and Wu, Nicolas and Yallop, Jeremy and Wang, Meng},
title={{Staging with Class: A Specification for Typed Template Haskell}},
year = {2022},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {POPL},
url = {https://doi.org/10.1145/3498723},
doi = {10.1145/3498723},
abstract = {Multi-stage programming using typed code quotation is an established technique for writing optimizing code generators with strong type-safety guarantees. Unfortunately, quotation in Haskell interacts poorly with type classes, making it difficult to write robust multi-stage programs. We study this unsound interaction and propose a resolution, staged type class constraints, which we formalize in a source calculus λ⇒ that elaborates into an explicit core calculus F. We show type soundness of both calculi, establishing that well-typed, well-staged source programs always elaborate to well-typed, well-staged core programs, and prove beta and eta rules for code quotations. Our design allows programmers to incorporate type classes into multi-stage programs with confidence. Although motivated by Haskell, it is also suitable as a foundation for other languages that support both overloading and quotation.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {61},
numpages = {30},
keywords = {Staging, Type Classes, Typed Template Haskell}
}
@inproceedings{patterson2022,
  title = {{Semantic Soundness for Language Interoperability}},
  author = {Patterson, Daniel and Mushtak, Noble and Wagner, Andrew and Ahmed, Amal},
  year = 2022,
  booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  location = {San Diego, CA, USA},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {PLDI 2022},
  pages = {609–624},
  doi = {10.1145/3519939.3523703},
  isbn = 9781450392655,
  url = {https://doi.org/10.1145/3519939.3523703},
  abstract = {Programs are rarely implemented in a single language, and thus questions of type soundness should address not only the semantics of a single language, but how it interacts with others. Even between type-safe languages, disparate features can frustrate interoperability, as invariants from one language can easily be violated in the other. In their seminal 2007 paper, Matthews and Findler proposed a multi-language construction that augments the interoperating languages with a pair of boundaries that allow code from one language to be embedded in the other. While this technique has been widely applied, their syntactic source-level interoperability doesn’t reflect practical implementations, where the behavior of interaction is only defined after compilation to a common target, and any safety must be ensured by target invariants or inserted target-level “glue code.” In this paper, we present a novel framework for the design and verification of sound language interoperability that follows an interoperation-after-compilation strategy. Language designers specify what data can be converted between types of the two languages via a convertibility relation τA ∼ τB (“τA is convertible to τB”) and specify target-level glue code implementing the conversions. Then, by giving a semantic model of source-language types as sets of target-language terms, they can establish not only the meaning of the source types, but also soundness of conversions: i.e., whenever τA ∼ τB, the corresponding pair of conversions (glue code) convert target terms that behave like τA to target terms that behave like τB, and vice versa. With this, they can prove semantic type soundness for the entire system. We illustrate our framework via a series of case studies that demonstrate how our semantic interoperation-after-compilation approach allows us both to account for complex differences in language semantics and make efficiency trade-offs based on particularities of compilers or targets.},
  numpages = 16,
  keywords = {logical relations, semantics, type soundness, language interoperability}
}
@inproceedings{cheung2022,
  title = {{Overcoming Restraint: Composing Verification of Foreign Functions with Cogent}},
  author = {Cheung, Louis and O'Connor, Liam and Rizkallah, Christine},
  year = 2022,
  booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs},
  location = {Philadelphia, PA, USA},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {CPP 2022},
  pages = {13–26},
  doi = {10.1145/3497775.3503686},
  isbn = 9781450391825,
  url = {https://doi.org/10.1145/3497775.3503686},
  abstract = {Cogent is a restricted functional language designed to reduce the cost of developing verified systems code. Because of its sometimes-onerous restrictions, such as the lack of support for recursion and its strict uniqueness type system, Cogent provides an escape hatch in the form of a foreign function interface (FFI) to C code. This poses a problem when verifying Cogent programs, as imported C components do not enjoy the same level of static guarantees that Cogent does. Previous verification of file systems implemented in Cogent merely assumed that their C components were correct and that they preserved the invariants of Cogent’s type system. In this paper, we instead prove such obligations. We demonstrate how they smoothly compose with existing Cogent theorems, and result in a correctness theorem of the overall Cogent-C system. The Cogent FFI constraints ensure that key invariants of Cogent’s type system are maintained even when calling C code. We verify reusable higher-order and polymorphic functions including a generic loop combinator and array iterators and demonstrate their application to several examples including binary search and the BilbyFs file system. We demonstrate the feasibility of verification of mixed Cogent-C systems, and provide some insight into verification of software comprised of code in multiple languages with differing levels of static guarantees.},
  numpages = 14,
  keywords = {data-structures, compilers, type-systems, language interoperability, verification}
}
@book{madhavapeddy2022real,
  title = {{Real World OCaml: Functional Programming for the Masses}},
  author = {Madhavapeddy, Anil and Minsky, Yaron},
  year = 2022,
  publisher = {Cambridge University Press},
  edition = "2nd",
  isbn={978-1009125802}
}
@inproceedings{patterson2023,
  title = {{Semantic Encapsulation Using Linking Types}},
  author = {Patterson, Daniel and Wagner, Andrew and Ahmed, Amal},
  year = 2023,
  booktitle = {Proceedings of the 8th ACM SIGPLAN International Workshop on Type-Driven Development},
  location = {Seattle, WA, USA},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  series = {TyDe 2023},
  pages = {14–28},
  doi = {10.1145/3609027.3609405},
  isbn = 9798400702990,
  url = {https://doi.org/10.1145/3609027.3609405},
  abstract = {Interoperability pervades nearly all mainstream language implementations, as most systems leverage subcomponents written in different languages. And yet, such linking can expose a language to foreign behaviors that are internally inexpressible, which poses a serious threat to safety invariants and programmer reasoning. To preserve such invariants, a language may try to add features to limit the reliance on external libraries, but endless extensions can obscure the core abstractions the language was designed to provide. In this paper, we outline an approach that encapsulates foreign code in a sound way—i.e., without disturbing the invariants promised by types of the core language. First, one introduces novel linking types that characterize the behaviors of foreign libraries that are inexpressible in the core language. To reason about the soundness of linking, one constructs a realizability model that captures the meaning of both core types and linking types as sets of target-language terms. Using this model, one can formally prove when foreign behavior is encapsulated; that is, unobservable to core code. We show one way to discharge such proofs automatically by augmenting the compiler to insert verified encapsulation wrappers around components that use foreign libraries. Inspired by existing approaches to FFIs, we develop a pair of case studies that extend a pure, functional language: one extension for state, and another for exceptions. The first allows us to implement mutable references via a library, whereas the second allows us to implement try and catch as library functions. Both extensions and the overall system are proven sound using logical relations that use realizability techniques.},
  numpages = 15,
  keywords = {linking, type soundness, semantics, language interoperability, logical relations}
}

@book{appel2014program,
author = {Appel, Andrew W. and Dockins, Robert and Hobor, Aquinas and Beringer, Lennart and Dodds, Josiah and Stewart, Gordon and Blazy, Sandrine and Leroy, Xavier},
title = {Program Logics for Certified Compilers},
year = {2014},
isbn = {110704801X},
publisher = {Cambridge University Press},
address = {USA},
abstract = {Separation Logic is the twenty-first-century variant of Hoare Logic that permits verification of pointer-manipulating programs. This book covers practical and theoretical aspects of Separation Logic at a level accessible to beginning graduate students interested in software verification. On the practical side it offers an introduction to verification in Hoare and Separation logics, simple case studies for toy languages, and the Verifiable C program logic for the C programming language. On the theoretical side it presents separation algebras as models of separation logics; step-indexed models of higher-order logical features for higher-order programs; indirection theory for constructing step-indexed separation algebras; tree-shares as models for shared ownership; and the semantic construction (and soundness proof) of Verifiable C. In addition, the book covers several aspects of the CompCert verified C compiler, and its connection to foundationally verified software analysis tools. All constructions and proofs are made rigorous and accessible in the Coq developments of the open-source Verified Software Toolchain.}
}
@article{aydemir2008,
author = {Aydemir, Brian and Chargu\'{e}raud, Arthur and Pierce, Benjamin C. and Pollack, Randy and Weirich, Stephanie},
title = {{Engineering Formal Metatheory}},
year = {2008},
issue_date = {January 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/1328897.1328443},
doi = {10.1145/1328897.1328443},
abstract = {Machine-checked proofs of properties of programming languages have become acritical need, both for increased confidence in large and complex designsand as a foundation for technologies such as proof-carrying code. However, constructing these proofs remains a black art, involving many choices in the formulation of definitions and theorems that make a huge cumulative difference in the difficulty of carrying out large formal developments. There presentation and manipulation of terms with variable binding is a key issue.We propose a novel style for formalizing metatheory, combining locally nameless representation of terms and cofinite quantification of free variable names in inductivedefinitions of relations on terms (typing, reduction, ...). The key technical insight is that our use of cofinite quantification obviates the need for reasoning about equivariance (the fact that free names can be renamed in derivations); in particular, the structural induction principles of relations defined using cofinite quantification are strong enough for metatheoretic reasoning, and need not be explicitly strengthened. Strong inversion principles follow (automatically, in Coq) from the induction principles. Although many of the underlying ingredients of our technique have been used before, their combination here yields a significant improvement over other methodologies using first-order representations, leading to developments that are faithful to informal practice, yet require noexternal tool support and little infrastructure within the proof assistant.We have carried out several large developments in this style using the Coq proof assistant and have made them publicly available. Our developments include type soundness for System F sub; and core ML (with references, exceptions, datatypes, recursion, and patterns) and subject reduction for the Calculus of Constructions. Not only do these developments demonstrate the comprehensiveness of our approach; they have also been optimized for clarity and robustness, making them good templates for future extension.},
journal = {SIGPLAN Not.},
month = {Jan},
pages = {3–15},
numpages = {13},
keywords = {binding, locally nameless, coq}
}

@inproceedings{de1972lambda,
  title={{Lambda Calculus Notation with Nameless Dummies, A Tool for Automatic Formula Manipulation, with Application to the Church-Rosser Theorem}},
  author={{de Bruijn}, Nicolaas Govert},
  booktitle={Indagationes Mathematicae (Proceedings)},
  volume={75},
  number={5},
  pages={381--392},
  year={1972},
  organization={Elsevier},
  url={https://doi.org/10.1016/1385-7258(72)90034-0}
}

@book{abelson1996structure,
  title={{Structure and Interpretation of Computer Programs}},
  author={Abelson, Harold and Sussman, Gerald Jay},
  year={1996},
  publisher={{The MIT Press}},
  isbn={978-0262510875},
  edition = "2nd"
}
@InProceedings{johnsson1985lambda,
author="Johnsson, Thomas",
editor="Jouannaud, Jean-Pierre",
title={{Lambda Lifting: Transforming Programs to Recursive Equations}},
booktitle="Functional Programming Languages and Computer Architecture",
year="1985",
publisher="Springer",
address="Berlin, Heidelberg",
pages="190--203",
abstract="Lambda lifting is a technique for transforming a functional program with local function definitions, possibly with free variables in the function definitions, into a program consisting only of global function (combinator) definitions which will be used as rewrite rules. Different ways of doing lambda lifting are presented, as well as reasons for rejecting or selecting the method used in our Lazy ML compiler. A functional program implementing the chosen algorithm is given.",
isbn="978-3-540-39677-2",
url={https://doi.org/10.1007/3-540-15975-4_37}
}

@article{wang2019graph,
author = {Wang, Shengyi and Cao, Qinxiang and Mohan, Anshuman and Hobor, Aquinas},
title = {{Certifying Graph-Manipulating C Programs via Localizations within Data Structures}},
year = {2019},
issue_date = {October 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {OOPSLA},
url = {https://doi.org/10.1145/3360597},
doi = {10.1145/3360597},
abstract = {We develop powerful and general techniques to mechanically verify realistic programs that manipulate heap-represented graphs. These graphs can exhibit well-known organization principles, such as being a directed acyclic graph or a disjoint-forest; alternatively, these graphs can be totally unstructured. The common thread for such structures is that they exhibit deep intrinsic sharing and can be expressed using the language of graph theory. We construct a modular and general setup for reasoning about abstract mathematical graphs and use separation logic to define how such abstract graphs are represented concretely in the heap. We develop a Localize rule that enables modular reasoning about such programs, and show how this rule can support existential quantifiers in postconditions and smoothly handle modified program variables. We demonstrate the generality and power of our techniques by integrating them into the Verified Software Toolchain and certifying the correctness of seven graph-manipulating programs written in CompCert C, including a 400-line generational garbage collector for the CertiCoq project. While doing so, we identify two places where the semantics of C is too weak to define generational garbage collectors of the sort used in the OCaml runtime. Our proofs are entirely machine-checked in Coq.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {171},
numpages = {30},
keywords = {VST, Separation logic, Graph-manipulating programs, Coq, CompCert}
}
@phdthesis{shengyi2020mechanized,
  title={{Mechanized Verification of Graph-Manipulating Programs}},
  author={Shengyi Wang},
  year={2020},
  school={National University of Singapore},
  url={https://web.archive.org/web/20231212164913/https://www.cs.princeton.edu/~shengyiw/resource/thesis.pdf}
}
@inproceedings{gibbons2014folding,
author = {Gibbons, Jeremy and Wu, Nicolas},
title = {{Folding Domain-Specific Languages: Deep and Shallow Embeddings (Functional Pearl)}},
year = {2014},
isbn = {9781450328739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2628136.2628138},
doi = {10.1145/2628136.2628138},
abstract = {A domain-specific language can be implemented by embedding within a general-purpose host language. This embedding may be deep or shallow, depending on whether terms in the language construct syntactic or semantic representations. The deep and shallow styles are closely related, and intimately connected to folds; in this paper, we explore that connection.},
booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
pages = {339–347},
numpages = {9},
keywords = {folds, domain-specific languages, deep and shallow embedding},
location = {Gothenburg, Sweden},
series = {ICFP '14}
}

@article{appel1993hash,
  title={{Hash-Consing Garbage Collection}},
  author={Appel, {Andrew W.} and Gon{\c{c}}alves, {Marcelo J. R.}},
  year={1993},
  url={https://web.archive.org/web/20220520152504/https://www.cs.princeton.edu/~appel/papers/hashgc.pdf}
}

@article{appel2015sha256,
author = {Appel, Andrew W.},
title = {{Verification of a Cryptographic Primitive: SHA-256}},
year = {2015},
issue_date = {April 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
issn = {0164-0925},
url = {https://doi.org/10.1145/2701415},
doi = {10.1145/2701415},
abstract = {This article presents a full formal machine-checked verification of a C program: the OpenSSL implementation of SHA-256. This is an interactive proof of functional correctness in the Coq proof assistant, using the Verifiable C program logic. Verifiable C is a separation logic for the C language, proved sound with respect to the operational semantics for C, connected to the CompCert verified optimizing C compiler.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {apr},
articleno = {7},
numpages = {31},
keywords = {Cryptography}
}

@inproceedings{meier2023certicoq,
  title={{CertiCoq-Wasm: Verified Compilation from Coq to WebAssembly}},
  author={Meier, Wolfgang and Pichon-Pharabod, Jean and Spitters, Bas},
  year={2023},
  booktitle = {the 10th International Workshop on Coq for Programming Languages (CoqPL)},
  url={https://web.archive.org/web/20240401020120/https://womeier.de/files/certicoqwasm-coqpl24-abstract.pdf}
}
@inproceedings{jones1993glasgow,
  title={{The Glasgow Haskell Compiler: A Technical Overview}},
  author={{Peyton Jones}, Simon L. and Hall, Cordy and Hammond, Kevin and Partain, Will and Wadler, Philip},
  booktitle={Proc. UK Joint Framework for Information Technology (JFIT) Technical Conference},
  volume={93},
  year={1993},
  url={https://web.archive.org/web/20220121100953/https://www.microsoft.com/en-us/research/wp-content/uploads/1993/03/grasp-jfit.pdf}
}
@incollection{marlow2004glasgow,
  title={{The Glasgow Haskell Compiler}},
  author={Marlow, Simon and {Peyton Jones}, Simon},
  year={2004},
  booktitle={{The Architecture of Open Source Applications}},
  volume=2,
  url={https://web.archive.org/web/20221212192523/https://simon.peytonjones.org/assets/pdfs/glasgow-haskell-compiler.pdf}
}
@InProceedings{brady2021idris,
  author =	{Brady, Edwin},
  title =	{{Idris 2: Quantitative Type Theory in Practice}},
  booktitle =	{35th European Conference on Object-Oriented Programming (ECOOP 2021)},
  pages =	{9:1--9:26},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-190-0},
  ISSN =	{1868-8969},
  year =	{2021},
  volume =	{194},
  editor =	{M{\o}ller, Anders and Sridharan, Manu},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ECOOP.2021.9},
  URN =		{urn:nbn:de:0030-drops-140527},
  doi =		{10.4230/LIPIcs.ECOOP.2021.9},
  annote =	{Keywords: Dependent types, linear types, concurrency}
}


@inproceedings{matsakis2014rust,
author = {Matsakis, Nicholas D. and Klock, Felix S.},
title = {{The Rust Language}},
year = {2014},
isbn = {9781450332170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2663171.2663188},
doi = {10.1145/2663171.2663188},
abstract = {Rust is a new programming language for developing reliable and efficient systems. It is designed to support concurrency and parallelism in building applications and libraries that take full advantage of modern hardware. Rust's static type system is safe and expressive and provides strong guarantees about isolation, concurrency, and memory safety.Rust also offers a clear performance model, making it easier to predict and reason about program efficiency. One important way it accomplishes this is by allowing fine-grained control over memory representations, with direct support for stack allocation and contiguous record storage. The language balances such controls with the absolute requirement for safety: Rust's type system and runtime guarantee the absence of data races, buffer overflows, stack overflows, and accesses to uninitialized or deallocated memory.},
booktitle = {Proceedings of the 2014 ACM SIGAda Annual Conference on High Integrity Language Technology},
pages = {103–104},
numpages = {2},
keywords = {affine type systems, memory management, rust, systems programming},
location = {Portland, Oregon, USA},
series = {HILT '14}
}

@article{sozeau2019equations,
author = {Sozeau, Matthieu and Mangin, Cyprien},
title = {{Equations Reloaded: High-Level Dependently-Typed Functional Programming and Proving in Coq}},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {ICFP},
url = {https://doi.org/10.1145/3341690},
doi = {10.1145/3341690},
abstract = {Equations is a plugin for the Coq proof assistant which provides a notation for defining programs by dependent pattern-matching and structural or well-founded recursion. It additionally derives useful high-level proof principles for demonstrating properties about them, abstracting away from the implementation details of the function and its compiled form. We present a general design and implementation that provides a robust and expressive function definition package as a definitional extension to the Coq kernel. At the core of the system is a new simplifier for dependent equalities based on an original handling of the no-confusion property of constructors.},
journal = {Proc. ACM Program. Lang.},
month = {jul},
articleno = {86},
numpages = {29},
keywords = {dependent pattern-matching, proof assistants, recursion}
}

@InProceedings{leino2010dafny,
author="Leino, K. Rustan M.",
editor="Clarke, Edmund M.
and Voronkov, Andrei",
title={{Dafny: An Automatic Program Verifier for Functional Correctness}},
booktitle="Logic for Programming, Artificial Intelligence, and Reasoning",
year="2010",
publisher="Springer",
address="Berlin, Heidelberg",
pages="348--370",
abstract="Traditionally, the full verification of a program's functional correctness has been obtained with pen and paper or with interactive proof assistants, whereas only reduced verification tasks, such as extended static checking, have enjoyed the automation offered by satisfiability-modulo-theories (SMT) solvers. More recently, powerful SMT solvers and well-designed program verifiers are starting to break that tradition, thus reducing the effort involved in doing full verification.",
isbn="978-3-642-17511-4",
url={https://doi.org/10.1007/978-3-642-17511-4_20}
}



@Inbook{Clarke2012,
author="Clarke, Edmund M.
and Klieber, William
and Nov{\'a}{\v{c}}ek, Milo{\v{s}}
and Zuliani, Paolo",
editor="Meyer, Bertrand
and Nordio, Martin",
title={{Model Checking and the State Explosion Problem}},
bookTitle="Tools for Practical Software Verification: LASER, International Summer School 2011, Elba Island, Italy, Revised Tutorial Lectures",
year="2012",
publisher="Springer",
address="Berlin, Heidelberg",
pages="1--30",
abstract="Model checking is an automatic verification technique for hardware and software systems that are finite state or have finite state abstractions. It has been used successfully to verify computer hardware, and it is beginning to be used to verify computer software as well. As the number of state variables in the system increases, the size of the system state space grows exponentially. This is called the ``state explosion problem''. Much of the research in model checking over the past 30 years has involved developing techniques for dealing with this problem. In these lecture notes, we will explain how the basic model checking algorithms work and describe some recent approaches to the state explosion problem, with an emphasis on Bounded Model Checking.",
isbn="978-3-642-35746-6",
doi="10.1007/978-3-642-35746-6_1",
url="https://doi.org/10.1007/978-3-642-35746-6_1"
}

@book{constable1986nuprl,
author = {Constable, R. L. and Allen, S. F. and Bromley, H. M. and Cleaveland, W. R. and Cremer, J. F. and Harper, R. W. and Howe, D. J. and Knoblock, T. B. and Mendler, N. P. and Panangaden, P. and Sasaki, J. T. and Smith, S. F.},
title = {{Implementing Mathematics with the Nuprl Proof Development System}},
year = {1986},
isbn = {0134518322},
publisher = {Prentice-Hall, Inc.},
address = {USA}
}

@InProceedings{letouzey2008extraction,
author="Letouzey, Pierre",
editor="Beckmann, Arnold
and Dimitracopoulos, Costas
and L{\"o}we, Benedikt",
title={{Extraction in Coq: An Overview}},
booktitle="Logic and Theory of Algorithms",
year="2008",
publisher="Springer",
address="Berlin, Heidelberg",
pages="359--369",
abstract="The extraction mechanism of Coq allows one to transform Coq proofs and functions into functional programs. We illustrate the behavior of this tool by reviewing several variants of Coq definitions for Euclidean division, as well as some more advanced examples. We then continue with a more general description of this tool: key features, main examples, strengths, limitations and perspectives.",
isbn="978-3-540-69407-6",
url={https://doi.org/10.1007/978-3-540-69407-6_39#citeas}
}

@inproceedings{chargueraud2010,
author = {Chargu\'{e}raud, Arthur},
title = {{Program Verification Through Characteristic Formulae}},
year = {2010},
isbn = {9781605587943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1863543.1863590},
doi = {10.1145/1863543.1863590},
abstract = {This paper describes CFML, the first program verification tool based on characteristic formulae. Given the source code of a pure Caml program, this tool generates a logical formula that implies any valid post-condition for that program. One can then prove that the program satisfies a given specification by reasoning interactively about the characteristic formula using a proof assistant such as Coq. Our characteristic formulae improve over Honda et al's total characteristic assertion pairs in that they are expressible in standard higher-order logic, allowing to exploit them in practice to verify programs using existing proof assistants. Our technique has been applied to formally verify more than half of the content of Okasaki's Purely Functional Data Structures reference book},
booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
pages = {321–332},
numpages = {12},
keywords = {total correctness, functional program, characteristic formula},
location = {Baltimore, Maryland, USA},
series = {ICFP '10}
}

@inproceedings{chargueraud2011,
author = {Chargu\'{e}raud, Arthur},
title = {{Characteristic Formulae for the Verification of Imperative Programs}},
year = {2011},
isbn = {9781450308656},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2034773.2034828},
doi = {10.1145/2034773.2034828},
abstract = {In previous work, we introduced an approach to program verification based on characteristic formulae. The approach consists of generating a higher-order logic formula from the source code of a program. This characteristic formula is constructed in such a way that it gives a sound and complete description of the semantics of that program. The formula can thus be exploited in an interactive proof assistant to formally verify that the program satisfies a particular specification.This previous work was, however, only concerned with purely-functional programs. In the present paper, we describe the generalization of characteristic formulae to an imperative programming language. In this setting, characteristic formulae involve specifications expressed in the style of Separation Logic. They also integrate the frame rule, which enables local reasoning. We have implemented a tool based on characteristic formulae. This tool, called CFML, supports the verification of imperative Caml programs using the Coq proof assistant. Using CFML, we have formally verified nontrivial imperative algorithms, as well as CPS functions, higher-order iterators, and programs involving higher-order stores.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
pages = {418–430},
numpages = {13},
keywords = {characteristic formula, interactive verification, total correctness},
location = {Tokyo, Japan},
series = {ICFP '11}
}

@inproceedings{pippenger96pure,
author = {Pippenger, Nicholas},
title = {{Pure versus Impure Lisp}},
year = {1996},
isbn = {0897917693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/237721.237741},
doi = {10.1145/237721.237741},
abstract = {The aspect of purity versus impurity that we address involves the absence versus presence of mutation: the use of primitives (RPLACA and RPLACD in Lisp, set-car! and set-cdr! in Scheme) that change the state of pairs without creating new pairs. It is well known that cyclic list structures can be created by impure programs, but not by pure ones. In this sense, impure Lisp is "more powerful" than pure Lisp. If the inputs and outputs of programs are restricted to be sequences of atomic symbols, however, this difference in computability disappears. We shall show that if the temporal sequence of input and output operations must be maintained (that is, if computations must be "online"), then a difference in complexity remains: for a pure program to do what an impure program does in n steps, O(n log n) steps are sufficient, and in some cases Ω(n log n) steps are necessary.},
booktitle = {Proceedings of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {104–109},
numpages = {6},
location = {St. Petersburg Beach, Florida, USA},
series = {POPL '96}
}

@article{amram1992pointers,
author = {Ben-Amram, Amir M. and Galil, Zvi},
title = {{On Pointers Versus Addresses}},
year = {1992},
issue_date = {July 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0004-5411},
url = {https://doi.org/10.1145/146637.146666},
doi = {10.1145/146637.146666},
journal = {J. ACM},
month = {jul},
pages = {617–648},
numpages = {32},
keywords = {random access memory, pointer structures, incompressibility}
}

@book{okasaki1999purely,
  title={{Purely Functional Data Structures}},
  author={Okasaki, Chris},
  year={1999},
  publisher={Cambridge University Press},
  isbn={978-0521663502}
}

@article{ponder1988applicative,
author = {Ponder, Carl G. and McGeer, Patrick and Ng, Anthony P-C.},
title = {{Are Applicative Languages Inefficient?}},
year = {1988},
issue_date = {June, 1988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/44546.44559},
doi = {10.1145/44546.44559},
abstract = {Side-effects are forbidden in applicative languages like Prolog [3], FP [2], pure Lisp [9], and SISAL [8]. Algorithms can often be reformulated applicatively with no loss of efficiency. It is not known whether this is always the case. Here are seven problems which have been resistant to efficient reformulation. The reader is invited to produce an efficient applicative program or lower-bound argument for any of these.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {135–139},
numpages = {5}
}

@inproceedings{dybvig2006chez,
    author = {Dybvig, R. Kent},
    title = {{The Development of Chez Scheme}},
    year = {2006},
    isbn = {1595933093},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1159803.1159805},
    doi = {10.1145/1159803.1159805},
    abstract = {Chez Scheme is now over 20 years old, the first version having been released in 1985. This paper takes a brief look back on the history of Chez Scheme's development to explore how and why it became the system it is today.},
    booktitle = {Proceedings of the Eleventh ACM SIGPLAN International Conference on Functional Programming},
    pages = {1–12},
    numpages = {12},
    keywords = {scheme implementation, chez scheme},
    location = {Portland, Oregon, USA},
    series = {ICFP '06}
    }

@article{korkutStarkAppel,
  title={{A Verified Foreign Function Interface Between Coq and C}},
  author={Korkut, Joomy and Stark, Kathrin and Appel, Andrew W.},
  year={2024},
  month={July},
  day=12,
  url={https://github.com/CertiCoq/VeriFFI/blob/62535e8e239197d09563cf5161ff1457718021e6/doc/veriffi_techreport.pdf}
}

@article{gueneau2023melocoton,
author = {Gu\'{e}neau, Arma\"{e}l and Hostert, Johannes and Spies, Simon and Sammler, Michael and Birkedal, Lars and Dreyer, Derek},
title = {{Melocoton: A Program Logic for Verified Interoperability Between OCaml and C}},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622823},
doi = {10.1145/3622823},
abstract = {In recent years, there has been tremendous progress on developing program logics for verifying the correctness of programs in a rich and diverse array of languages. Thus far, however, such logics have assumed that programs are written entirely in a single programming language. In practice, this assumption rarely holds since programs are often composed of components written in different programming languages, which interact with one another via some kind of foreign function interface (FFI). In this paper, we take the first steps towards the goal of developing program logics for multi-language verification. Specifically, we present Melocoton, a multi-language program verification system for reasoning about OCaml, C, and their interactions through the OCaml FFI. Melocoton consists of the first formal semantics of (a large subset of) the OCaml FFI—previously only described in prose in the OCaml manual—as well as the first program logic to reason about the interactions of program components written in OCaml and C. Melocoton is fully mechanized in Coq on top of the Iris separation logic framework.},
journal = {Proc. ACM Program. Lang.},
month = {oct},
articleno = {247},
numpages = {29},
keywords = {C, Coq, Iris, OCaml, angelic non-determinism, foreign-function interfaces, garbage collection, multi-language semantics, program logics, separation logic, transfinite step-indexing}
}

@inproceedings{cheung2022cogent,
author = {Cheung, Louis and O'Connor, Liam and Rizkallah, Christine},
title = {{Overcoming Restraint: Composing Verification of Foreign Functions with Cogent}},
year = {2022},
isbn = {9781450391825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3497775.3503686},
doi = {10.1145/3497775.3503686},
abstract = {Cogent is a restricted functional language designed to reduce the cost of developing verified systems code. Because of its sometimes-onerous restrictions, such as the lack of support for recursion and its strict uniqueness type system, Cogent provides an escape hatch in the form of a foreign function interface (FFI) to C code. This poses a problem when verifying Cogent programs, as imported C components do not enjoy the same level of static guarantees that Cogent does. Previous verification of file systems implemented in Cogent merely assumed that their C components were correct and that they preserved the invariants of Cogent’s type system. In this paper, we instead prove such obligations. We demonstrate how they smoothly compose with existing Cogent theorems, and result in a correctness theorem of the overall Cogent-C system. The Cogent FFI constraints ensure that key invariants of Cogent’s type system are maintained even when calling C code. We verify reusable higher-order and polymorphic functions including a generic loop combinator and array iterators and demonstrate their application to several examples including binary search and the BilbyFs file system. We demonstrate the feasibility of verification of mixed Cogent-C systems, and provide some insight into verification of software comprised of code in multiple languages with differing levels of static guarantees.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {13–26},
numpages = {14},
keywords = {verification, type-systems, language interoperability, data-structures, compilers},
location = {Philadelphia, PA, USA},
series = {CPP 2022}
}

@article{blume2001,
title = {{No-Longer-Foreign: Teaching an ML Compiler to Speak C “Natively”}},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {59},
number = {1},
pages = {36-52},
year = {2001},
note = {BABEL'01, First International Workshop on Multi-Language Infrastructure and Interoperability (Satellite Event of PLI 2001)},
issn = {1571-0661},
url = {https://doi.org/10.1016/S1571-0661(05)80452-9},
author = {Matthias Blume},
abstract = {We present a new foreign-function interface for SML/NJ. It is based on the idea of data-level interoperability—the ability of ML programs to inspect as well as manipulate C data structures directly. The core component of this work is an encoding of the almost2 complete C type system in ML types. The encoding makes extensive use of a “folklore” typing trick, taking advantage of ML's polymorphism, its type constructors, its abstraction mechanisms, and even functors. A small low-level component which deals with C struct and union declarations as well as program linkage is hidden from the programmer's eye by a simple program-generator tool that translates C declarations to corresponding ML glue code.}
}


@article{furr2005checking,
    author = {Furr, Michael and Foster, Jeffrey S.},
    title = {{Checking Type Safety of Foreign Function Calls}},
    year = {2005},
    isbn = {1595930566},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1065010.1065019},
    doi = {10.1145/1065010.1065019},
    abstract = {We present a multi-lingual type inference system for checking type safety across a foreign function interface. The goal of our system is to prevent foreign function calls from introducing type and memory safety violations into an otherwise safe language. Our system targets OCaml's FFI to C, which is relatively lightweight and illustrates some interesting challenges in multi-lingual type inference. The type language in our system embeds OCaml types in C types and vice-versa, which allows us to track type information accurately even through the foreign language, where the original types are lost. Our system uses representational types that can model multiple OCaml types, because C programs can observe that many OCaml types have the same physical representation. Furthermore, because C has a low-level view of OCaml data, our inference system includes a dataflow analysis to track memory offsets and tag information. Finally, our type system includes garbage collection information to ensure that pointers from the FFI to the OCaml heap are tracked properly. We have implemented our inference system and applied it to a small set of benchmarks. Our results show that programmers do misuse these interfaces, and our implementation has found several bugs and questionable coding practices in our benchmarks.},
    booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
    pages = {62–72},
    numpages = {11},
    keywords = {representational type, multi-lingual type system, multi-lingual type inference, foreign function interface, foreign function calls, flow-sensitive type system, dataflow analysis, OCaml, FFI},
    location = {Chicago, IL, USA},
    series = {PLDI '05}
}

@inproceedings{furr2006polymorphic,
  title={{Polymorphic Type Inference for the JNI}},
  author={Furr, Michael and Foster, Jeffrey S},
  booktitle={European Symposium on Programming},
  pages={309--324},
  year={2006},
  organization={Springer},
  url={https://doi.org/10.1007/11693024_21},
  doi={10.1007/11693024_21}
}

@article{furr2008checking,
author = {Furr, Michael and Foster, Jeffrey S.},
title = {{Checking Type Safety of Foreign Function Calls}},
year = {2008},
issue_date = {July 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {4},
issn = {0164-0925},
url = {https://doi.org/10.1145/1377492.1377493},
doi = {10.1145/1377492.1377493},
abstract = {Foreign function interfaces (FFIs) allow components in different languages to communicate directly with each other. While FFIs are useful, they often require writing tricky low-level code and include little or no static safety checking, thus providing a rich source of hard-to-find programming errors. In this article, we study the problem of enforcing type safety across the OCaml-to-C FFI and the Java Native Interface (JNI). We present O-Saffire and J-Saffire, a pair of multilingual type inference systems that ensure C code that uses these FFIs accesses high-level data safely. Our inference systems use representational types to model C's low-level view of OCaml and Java values, and singleton types to track integers, strings, memory offsets, and type tags through C. J-Saffire, our Java system, uses a polymorphic flow-insensitive, unification-based analysis. Polymorphism is important because it allows us to precisely model user-defined wrapper functions and the more than 200 JNI functions. O-Saffire, our OCaml system, uses a monomorphic flow-sensitive analysis because, while polymorphism is much less important for the OCaml FFI flow-sensitivity is critical to track conditional branches, which are used when pattern matching OCaml data in C. O-Saffire also tracks garbage collection information to ensure that local C pointers to the OCaml heap are registered properly, which is not necessary for the JNI. We have applied O-Saffire and J-Saffire to a set of benchmarks and found many bugs and questionable coding practices. These results suggest that static checking of FFIs can be a valuable tool in writing correct multilingual software.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {aug},
articleno = {18},
numpages = {63},
keywords = {representational type, multilingual type system, multilingual type inference, foreign function calls, flow-sensitive type system, dataflow analysis, OCaml, Java Native Interface, Java, JNI, Foreign function interface, FFI}
}

@inproceedings{mullen2018oeuf,
author = {Mullen, Eric and Pernsteiner, Stuart and Wilcox, James R. and Tatlock, Zachary and Grossman, Dan},
title = {{Œuf: Minimizing the Coq Extraction TCB}},
year = {2018},
isbn = {9781450355865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3167089},
doi = {10.1145/3167089},
abstract = {Verifying systems by implementing them in the programming language of a proof assistant (e.g., Gallina for Coq) lets us directly leverage the full power of the proof assistant for verifying the system. But, to execute such an implementation requires extraction, a large complicated process that is in the trusted computing base (TCB). This paper presents undefineduf, a verified compiler from a subset of Gallina to assembly. undefineduf’s correctness theorem ensures that compilation preserves the semantics of the source Gallina program. We describe how undefineduf’s specification can be used as a foreign function interface to reason about the interaction between compiled Gallina programs and surrounding shim code. Additionally, undefinedufmaintains a small TCB for its front-end by reflecting Gallina programs to undefinedufsource and automatically ensuring equivalence using computational denotation. This design enabled us to implement some early compiler passes (e.g., lambda lifting) in the untrusted reflection and ensure their correctness via translation validation. To evaluate undefineduf, we compile Appel’s SHA256 specification from Gallina to x86 and write a shim for the generated code, yielding a verified sha256sum implementation with a small TCB.},
booktitle = {Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {172–185},
numpages = {14},
keywords = {Compilers, Coq, Formal Verification, Verified Systems},
location = {Los Angeles, CA, USA},
series = {CPP 2018}
}

@inproceedings{letan2020freespec,
author = {Letan, Thomas and R\'{e}gis-Gianas, Yann},
title = {{FreeSpec: Specifying, Verifying, and Executing Impure Computations in Coq}},
year = {2020},
isbn = {9781450370974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3372885.3373812},
doi = {10.1145/3372885.3373812},
abstract = {FreeSpec is a framework for the Coq theorem prover which allows for specifying and verifying complex systems as hierarchies of components verified both in isolation and in composition. While FreeSpec was originally introduced for reasoning about hardware architectures, in this article we propose a novel iteration of FreeSpec formalism specifically designed to write certified programs and libraries. Then, we present in depth how we use this formalism to verify a static files webserver. We use this opportunity to present FreeSpec proof automation tactics, and to demonstrate how they successfully erase FreeSpec internal definitions to let users focus on the core of their proofs. Finally, we introduce FreeSpec.Exec, a plugin for Coq to seamlessly execute certified programs written with FreeSpec.},
booktitle = {Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {32–46},
numpages = {15},
keywords = {proof automation, framework, certified programs, certified libraries, Coq},
location = {New Orleans, LA, USA},
series = {CPP 2020}
}

@article{letan2021modular,
author = {Letan, Thomas and R\'{e}gis-Gianas, Yann and Chifflier, Pierre and Hiet, Guillaume},
title = {{Modular Verification of Programs with Effects
and Effects Handlers}},
year = {2021},
issue_date = {Jan 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {33},
number = {1},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-020-00523-2},
doi = {10.1007/s00165-020-00523-2},
abstract = {Modern computing systems have grown in complexity, and even though system components are generally carefully designed and even verified by different groups of people, the composition of these components is often regarded with less attention. Inconsistencies between components’ assumptions on the rest of the system can have significant repercussions on this system, and may ultimately lead to safety or security issues. In this article, we introduce FreeSpec, a formalismbuilt upon the key idea that components can bemodeled as programs with algebraic effects to be realized by other components. FreeSpec allows for the modular modeling of a complex system, by defining idealized components connected together, and the modular verification of the properties of their composition. In addition, we have implemented a framework for the Coq proof assistant based on FreeSpec.},
journal = {Form. Asp. Comput.},
month = {jan},
pages = {127–150},
numpages = {24},
keywords = {Formal verification, Coq}
}

@article{xia2019itrees,
author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
title = {{Interaction Trees: Representing Recursive and Impure Programs in Coq}},
year = {2019},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {POPL},
url = {https://doi.org/10.1145/3371119},
doi = {10.1145/3371119},
abstract = {Interaction trees (ITrees) are a general-purpose data structure for representing the behaviors of recursive programs that interact with their environments. A coinductive variant of “free monads,” ITrees are built out of uninterpreted events and their continuations. They support compositional construction of interpreters from event handlers, which give meaning to events by defining their semantics as monadic actions. ITrees are expressive enough to represent impure and potentially nonterminating, mutually recursive computations, while admitting a rich equational theory of equivalence up to weak bisimulation. In contrast to other approaches such as relationally specified operational semantics, ITrees are executable via code extraction, making them suitable for debugging, testing, and implementing software artifacts that are amenable to formal verification. We have implemented ITrees and their associated theory as a Coq library, mechanizing classic domain- and category-theoretic results about program semantics, iteration, monadic structures, and equational reasoning. Although the internals of the library rely heavily on coinductive proofs, the interface hides these details so that clients can use and reason about ITrees without explicit use of Coq’s coinduction tactics. To showcase the utility of our theory, we prove the termination-sensitive correctness of a compiler from a simple imperative source language to an assembly-like target whose meanings are given in an ITree-based denotational semantics. Unlike previous results using operational techniques, our bisimulation proof follows straightforwardly by structural induction and elementary rewriting via an equational theory of combinators for control-flow graphs.},
journal = {Proc. ACM Program. Lang.},
month = {dec},
articleno = {51},
numpages = {32},
keywords = {monads, compiler correctness, coinduction, Coq}
}

@inproceedings{koh2019itrees,
author = {Koh, Nicolas and Li, Yao and Li, Yishuai and Xia, Li-yao and Beringer, Lennart and Honor\'{e}, Wolf and Mansky, William and Pierce, Benjamin C. and Zdancewic, Steve},
title = {{From C to Interaction Trees: Specifying, Verifying, and Testing a Networked Server}},
year = {2019},
isbn = {9781450362221},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293880.3294106},
doi = {10.1145/3293880.3294106},
abstract = {We present the first formal verification of a networked server implemented in C. Interaction trees, a general structure for representing reactive computations, are used to tie together disparate verification and testing tools (Coq, VST, and QuickChick) and to axiomatize the behavior of the operating system on which the server runs (CertiKOS). The main theorem connects a specification of acceptable server behaviors, written in a straightforward “one client at a time” style, with the CompCert semantics of the C program. The variability introduced by low-level buffering of messages and interleaving of multiple TCP connections is captured using network refinement, a variant of observational refinement.},
booktitle = {Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs},
pages = {234–248},
numpages = {15},
keywords = {testing, network refinement, interaction trees, formal verification, VST, TCP, QuickChick},
location = {Cascais, Portugal},
series = {CPP 2019}
}

@inproceedings{mcbride2010outrageous,
author = {McBride, Conor},
title = {{Outrageous but Meaningful Coincidences: Dependent Type-Safe Syntax and Evaluation}},
year = {2010},
isbn = {9781450302517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1863495.1863497},
doi = {10.1145/1863495.1863497},
abstract = {Tagless interpreters for well-typed terms in some object language are a standard example of the power and benefit of precise indexing in types, whether with dependent types, or generalized algebraic datatypes. The key is to reflect object language types as indices (however they may be constituted) for the term datatype in the host language, so that host type coincidence ensures object type coincidence. Whilst this technique is widespread for simply typed object languages, dependent types have proved a tougher nut with nontrivial computation in type equality. In their type-safe representations, Danielsson [2006] and Chapman [2009] succeed in capturing the equality rules, but at the cost of representing equality derivations explicitly within terms. This article constructs a type-safe representation for a dependently typed object language, dubbed KIPLING, whose computational type equality just appropriates that of its host, Agda. The KIPLING interpreter example is not merely de rigeur - it is key to the construction. At the heart of the technique is that key component of generic programming, the universe.},
booktitle = {Proceedings of the 6th ACM SIGPLAN Workshop on Generic Programming},
pages = {1–12},
numpages = {12},
keywords = {dependent types, generic programming},
location = {Baltimore, Maryland, USA},
series = {WGP '10}
}

@InProceedings{prinz2022deeper,
  author =	{Prinz, Jacob and Kavvos, G. A. and Lampropoulos, Leonidas},
  title =	{{Deeper Shallow Embeddings}},
  booktitle =	{13th International Conference on Interactive Theorem Proving (ITP 2022)},
  pages =	{28:1--28:18},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-252-5},
  ISSN =	{1868-8969},
  year =	{2022},
  volume =	{237},
  editor =	{Andronick, June and de Moura, Leonardo},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  url={https://doi.org/10.4230/LIPIcs.ITP.2022.28}
}

@InProceedings{turcotte2019reasoning,
  author =	{Turcotte, Alexi and Arteca, Ellen and Richards, Gregor},
  title =	{{Reasoning About Foreign Function Interfaces Without Modelling the Foreign Language}},
  booktitle =	{33rd European Conference on Object-Oriented Programming (ECOOP 2019)},
  pages =	{16:1--16:32},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-111-5},
  ISSN =	{1868-8969},
  year =	{2019},
  volume =	{134},
  editor =	{Donaldson, Alastair F.},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://doi.org/10.4230/LIPIcs.ECOOP.2019.16}
}

@InProceedings{trifonov1999safe,
author="Trifonov, Valery
and Shao, Zhong",
editor="Swierstra, S. Doaitse",
title="Safe and Principled Language Interoperation",
booktitle="Programming Languages and Systems",
year="1999",
publisher="Springer",
address="Berlin, Heidelberg",
pages="128--146",
abstract="Safety of interoperation of program fragments written in different safe languages may fail when the languages have different systems of computational effects: an exception raised by an ML function may have no valid semantic interpretation in the context of a Safe-C caller. Sandboxing costs performance and still may violate the semantics if effects are not taken into account.We show that effect annotations alone are insufficient to guarantee safety, and we present a type system with bounded effect polymorphism designed to verify the compatibility of abstract resources required by the computational models of the interoperating languages. The type system ensures single address space interoperability of statically typed languages with effect mechanisms built of modules for control and state. It is shown sound for safety with respect to the semantics of a language with constructs for selection, simulation, and blocking of resources, targeted as an intermediate language for optimization of resource handling.",
isbn="978-3-540-49099-9",
url={https://doi.org/10.1007/3-540-49099-X_9}
}

@InProceedings{svenningsson2013combining,
author="Svenningsson, Josef
and Axelsson, Emil",
editor="Loidl, Hans-Wolfgang
and Pe{\~{n}}a, Ricardo",
title={{Combining Deep and Shallow Embedding for EDSL}},
booktitle="Trends in Functional Programming",
year="2013",
publisher="Springer",
address="Berlin, Heidelberg",
pages="21--36",
abstract="When compiling embedded languages it is natural to use an abstract syntax tree to represent programs. This is known as a deep embedding and it is a rather cumbersome technique compared to other forms of embedding, typically leading to more code and being harder to extend. In shallow embeddings, language constructs are mapped directly to their semantics which yields more flexible and succinct implementations. But shallow embeddings are not well-suited for compiling embedded languages. We present a technique to combine deep and shallow embedding in the context of compiling embedded languages in order to provide the benefits of both techniques. In particular it helps keeping the deep embedding small and it makes extending the embedded language much easier. Our technique also has some unexpected but welcome knock-on effects. It provides fusion of functions to remove intermediate results for free without any additional effort. It also helps to give the embedded language a more natural programming interface.",
isbn="978-3-642-40447-4",
url={https://doi.org/10.1007/978-3-642-40447-4_2}
}

@manual{appel2023verifiable,
  title        = {{Verifiable C - Applying the Verified Software Toolchain
to C Programs}},
  author       = {Appel, Andrew W. and Beringer, Lennart and Cao, Qinxiang and Dodds, Josiah},
  year         = 2023,
  month        = {January},
  url = {https://github.com/PrincetonUniversity/VST/raw/master/doc/VC.pdf}
}

@incollection{appel2023sf,
  author      = {Appel, Andrew W. and Beringer, Lennart and Cao, Qinxiang},
  title       = {{Verifiable C}},
  booktitle   = {{Software Foundations}},
  year        = 2023,
  chapter     = 5,
  url={https://softwarefoundations.cis.upenn.edu/vc-current/index.html},
  editor={Pierce, Benjamin C.}
}

@inproceedings{appel2022coq,
  title={{Coq’s Vibrant Ecosystem for Verification Engineering (invited talk)}},
  author={Appel, Andrew W.},
  booktitle={Proceedings of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs},
  pages={2--11},
  year={2022},
  url={https://doi.org/10.1145/3497775.3503951}
}

@article{appel2020floating,
  title={{C-Language Floating-Point Proofs Layered with VST and Flocq}},
  author={Appel, Andrew W. and Bertot, Yves},
  journal={Journal of Formalized Reasoning},
  volume={13},
  number={1},
  pages={1--16},
  year={2020},
  url={https://doi.org/10.6092/issn.1972-5787/11442}
}


@inproceedings{patterson2022semantic,
author = {Patterson, Daniel and Mushtak, Noble and Wagner, Andrew and Ahmed, Amal},
title = {{Semantic Soundness for Language Interoperability}},
year = {2022},
isbn = {9781450392655},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3519939.3523703},
doi = {10.1145/3519939.3523703},
abstract = {Programs are rarely implemented in a single language, and thus questions of type soundness should address not only the semantics of a single language, but how it interacts with others. Even between type-safe languages, disparate features can frustrate interoperability, as invariants from one language can easily be violated in the other. In their seminal 2007 paper, Matthews and Findler proposed a multi-language construction that augments the interoperating languages with a pair of boundaries that allow code from one language to be embedded in the other. While this technique has been widely applied, their syntactic source-level interoperability doesn’t reflect practical implementations, where the behavior of interaction is only defined after compilation to a common target, and any safety must be ensured by target invariants or inserted target-level “glue code.” In this paper, we present a novel framework for the design and verification of sound language interoperability that follows an interoperation-after-compilation strategy. Language designers specify what data can be converted between types of the two languages via a convertibility relation τA ∼ τB (“τA is convertible to τB”) and specify target-level glue code implementing the conversions. Then, by giving a semantic model of source-language types as sets of target-language terms, they can establish not only the meaning of the source types, but also soundness of conversions: i.e., whenever τA ∼ τB, the corresponding pair of conversions (glue code) convert target terms that behave like τA to target terms that behave like τB, and vice versa. With this, they can prove semantic type soundness for the entire system. We illustrate our framework via a series of case studies that demonstrate how our semantic interoperation-after-compilation approach allows us both to account for complex differences in language semantics and make efficiency trade-offs based on particularities of compilers or targets.},
booktitle = {Proceedings of the 43rd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
pages = {609–624},
numpages = {16},
keywords = {type soundness, semantics, logical relations, language interoperability},
location = {San Diego, CA, USA},
series = {PLDI 2022}
}

@article{baudon2023bit,
author = {Baudon, Tha\"{\i}s and Radanne, Gabriel and Gonnord, Laure},
title = {{Bit-Stealing Made Legal: Compilation for Custom Memory Representations of Algebraic Data Types}},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {ICFP},
url = {https://doi.org/10.1145/3607858},
doi = {10.1145/3607858},
abstract = {Initially present only in functional languages such as OCaml and Haskell, Algebraic Data Types (ADTs) have now become pervasive in mainstream languages, providing nice data abstractions and an elegant way to express functions through pattern matching. Unfortunately, ADTs remain seldom used in low-level programming. One reason is that their increased convenience comes at the cost of abstracting away the exact memory layout of values. Even Rust, which tries to optimize data layout, severely limits control over memory representation. In this article, we present a new approach to specify the data layout of rich data types based on a dual view: a source type, providing a high-level description available in the rest of the code, along with a memory type, providing full control over the memory layout. This dual view allows for better reasoning about memory layout, both for correctness, with dedicated validity criteria linking the two views, and for optimizations that manipulate the memory view. We then provide algorithms to compile constructors and destructors, including pattern matching, to their low-level memory representation. We prove our compilation algorithms correct, implement them in a tool called ribbit that compiles to LLVM IR, and show some early experimental results.},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {216},
numpages = {34},
keywords = {Algebraic Data Types, Compilation, Data Layouts, Pattern Matching}
}


@article{elsman2024double,
author = {Elsman, Martin},
title = {{Double-Ended Bit-Stealing for Algebraic Data Types}},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {ICFP},
url = {https://doi.org/10.1145/3674628},
doi = {10.1145/3674628},
journal = {Proc. ACM Program. Lang.},
month = {aug},
articleno = {239},
numpages = {33},
keywords = {Compilation, Data-type representations, Functional languages, Unboxing}
}

@article{chataing2024unboxed,
author = {Chataing, Nicolas and Dolan, Stephen and Scherer, Gabriel and Yallop, Jeremy},
title = {{Unboxed Data Constructors: Or, How cpp Decides a Halting Problem}},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632893},
doi = {10.1145/3632893},
abstract = {We propose a new language feature for ML-family languages, the ability to selectively unbox certain data constructors, so that their runtime representation gets compiled away to just the identity on their argument. Unboxing must be statically rejected when it could introduce confusion, that is, distinct values with the same representation. We discuss the use-case of big numbers, where unboxing allows to write code that is both efficient and safe, replacing either a safe but slow version or a fast but unsafe version. We explain the static analysis necessary to reject incorrect unboxing requests. We present our prototype implementation of this feature for the OCaml programming language, discuss several design choices and the interaction with advanced features such as Guarded Algebraic Datatypes. Our static analysis requires expanding type definitions in type expressions, which is not necessarily normalizing in presence of recursive type definitions. In other words, we must decide normalization of terms in the first-order λ-calculus with recursion. We provide an algorithm to detect non-termination on-the-fly during reduction, with proofs of correctness and completeness. Our algorithm turns out to be closely related to the normalization strategy for macro expansion in the cpp preprocessor.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {51},
numpages = {31},
keywords = {boxing, data representation, recursive definitions, sum types, tagging, termination}
}

@article{yallop2018modular,
  title={{A Modular Foreign Function Interface}},
  author={Yallop, Jeremy and Sheets, David and Madhavapeddy, Anil},
  journal={Science of Computer Programming},
  volume={164},
  pages={82--97},
  year={2018},
  publisher={Elsevier},
  url={https://doi.org/10.1016/j.scico.2017.04.002},
  doi={10.1016/j.scico.2017.04.002}
}


@inproceedings{matthews2007operational,
author = {Matthews, Jacob and Findler, Robert Bruce},
title = {{Operational Semantics for Multi-language Programs}},
year = {2007},
isbn = {1595935754},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1190216.1190220},
doi = {10.1145/1190216.1190220},
abstract = {Inter-language interoperability is big business, as the success of Microsoft's .NET and COM and Sun's JVM show. Programming language designers are designing programming languages that reflect that fact --- SML#, Mondrian, and Scala, to name just a few examples, all treat interoperability with other languages as a central design feature. Still, current multi-language research tends not to focus on the semantics of interoperation features, but only on how to implement them efficiently. In this paper, we take first steps toward higher-level models of interoperating systems. Our technique abstracts away the low-level details of interoperability like garbage collection and representation coherence, and lets us focus on semantic properties like type-safety and observable equivalence.Beyond giving simple expressive models that are natural compositions of single-language models, our studies have uncovered several interesting facts about interoperability. For example, higher-order contracts naturally emerge as the glue to ensure that interoperating languages respect each other's type systems. While we present our results in an abstract setting, they shed light on real multi-language systems and tools such as the JNI, SWIG, and Haskell's stable pointers.},
booktitle = {Proceedings of the 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {3–10},
numpages = {8},
keywords = {interoperability, multi-language systems, operational semantics},
location = {Nice, France},
series = {POPL '07}
}

@inproceedings{perconti2014verifying,
  title={{Verifying an Open Compiler Using Multi-language Semantics}},
  author={Perconti, James T and Ahmed, Amal},
  booktitle={Programming Languages and Systems: 23rd European Symposium on Programming, ESOP 2014, Held as Part of the European Joint Conferences on Theory and Practice of Software, ETAPS 2014, Grenoble, France, April 5-13, 2014, Proceedings 23},
  pages={128--148},
  year={2014},
  organization={Springer},
  doi={10.1007/978-3-642-54833-8_8},
  url={https://doi.org/10.1007/978-3-642-54833-8_8}
}


@article{kumar2014cakeml,
  title={{CakeML: A Verified Implementation of ML}},
  author={Kumar, Ramana and Myreen, Magnus O and Norrish, Michael and Owens, Scott},
  journal={ACM SIGPLAN Notices},
  volume={49},
  number={1},
  pages={179--191},
  year={2014},
  publisher={ACM New York, NY, USA},
  doi={10.1145/2578855.2535841},
  url={https://doi.org/10.1145/2578855.2535841}
}                  

@inproceedings{Gueneau2017,
author="Gu{\'e}neau, Arma{\"e}l
and Myreen, Magnus O.
and Kumar, Ramana
and Norrish, Michael",
title="{Verified Characteristic Formulae for {CakeML}}",
bookTitle="Programming Languages and Systems: 26th European Symposium on Programming, ESOP 2017, April 22--29, 2017, Proceedings",
year="2017",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="584--610",
abstract="Characteristic Formulae (CF) offer a productive, principled approach to generating verification conditions for higher-order imperative programs, but so far the soundness of CF has only been considered with respect to an informal specification of a programming language (OCaml). This leaves a gap between what is established by the verification framework and the program that actually runs. We present a fully-fledged CF framework for the formally specified CakeML programming language. Our framework extends the existing CF approach to support exceptions and I/O, thereby covering the full feature set of CakeML, and comes with a formally verified soundness theorem. Furthermore, it integrates with existing proof techniques for verifying CakeML programs. This validates the CF approach, and allows users to prove end-to-end theorems for higher-order imperative programs, from specification to language semantics, within a single theorem prover.",
isbn="978-3-662-54434-1",
doi="10.1007/978-3-662-54434-1_22",
url="https://doi.org/10.1007/978-3-662-54434-1_22"
}

@book{liang99:jni,
 author = "Sheng Liang",
 title={{Java Native Interface: Programmer's Guide and Reference}},
 publisher="Addison-Wesley Longman",
 year=1999,
 isbn={978-0-201-32577-5}
}

@inproceedings{tan2006safe,
  title={{Safe Java Native Interface}},
  author={Tan, Gang and Appel, Andrew W and Chakradhar, Srimat and Raghunathan, Anand and Ravi, Srivaths and Wang, Daniel},
  booktitle={IEEE International Symposium on Secure Software Engineering},
  volume={97},
  pages={106-119},
  year={2006}
}


@misc{camlidl99,
author="Xavier Leroy",
title="{CamlIDL User's Manual}",
month=mar,
year=1999,
url={https://caml.inria.fr/pub/old_caml_site/camlidl/htmlman/}}

@article{vst-floyd,
 author = {Cao, Qinxiang and Beringer, Lennart and Gruetter, Samuel and Dodds, Josiah and Appel, Andrew W.},
 title = {{{VST-Floyd}: A Separation Logic Tool to Verify Correctness of {C} Programs}},
 journal = {J. Autom. Reason.},
 issue_date = {June      2018},
 volume = {61},
 number = {1-4},
 month = jun,
 year = {2018},
 issn = {0168-7433},
 pages = {367--422},
 numpages = {56},
 url = {https://doi.org/10.1007/s10817-018-9457-5},
 doi = {10.1007/s10817-018-9457-5},
 acmid = {3230190},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
 keywords = {Program verification, Proof automation, Separation logic, Symbolic execution},
}

@phdthesis{frank2024kernel,
  author      = {Mario Frank},
  title       = {{On Synthesising Linux Kernel Module Components from Coq Formalisations}},
  school      = {Universit{\"a}t Potsdam},
  doi       = {10.25932/publishup-64255},
  url={https://doi.org/10.25932/publishup-64255},
  year        = {2024},
}

@misc{paykin2024set,
  author = {Paykin, Jennifer},
  title = {{certicoq-set-library: Using CertiCoq to implement a library for formally verified set in C++}},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jpaykin/certicoq-set-library}},
  commit = {63d2f307cbba75598b86bd681b1bff30184ad020}
}
@misc{carstens2022uvrooster,
  author = {Carstens, Tim},
  title = {{uvrooster: A High-Performance Runtime for the CertiCoq Compiler, Built on Coq and libuv}},
  year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/intoverflow/uvrooster}},
  commit = {0d3ecdf75199ec7fb3f1e8079089dab448ba3312}
}

@InProceedings{singhal2024optimizing,
  author =	{Singhal, Vidush and Koparkar, Chaitanya and Zullo, Joseph and Pelenitsyn, Artem and Vollmer, Michael and Rainey, Mike and Newton, Ryan and Kulkarni, Milind},
  title =	{{Optimizing Layout of Recursive Datatypes with Marmoset: Or, Algorithms \{+\} Data Layouts \{=\} Efficient Programs}},
  booktitle =	{38th European Conference on Object-Oriented Programming (ECOOP 2024)},
  pages =	{38:1--38:28},
  series =	{Leibniz International Proceedings in Informatics (LIPIcs)},
  ISBN =	{978-3-95977-341-6},
  ISSN =	{1868-8969},
  year =	{2024},
  volume =	{313},
  editor =	{Aldrich, Jonathan and Salvaneschi, Guido},
  publisher =	{Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address =	{Dagstuhl, Germany},
  URL =		{https://doi.org/10.4230/LIPIcs.ECOOP.2024.38},
  doi =		{10.4230/LIPIcs.ECOOP.2024.38},
  annote =	{Keywords: Tree traversals, Compilers, Data layout optimization, Dense data layout}
}

@article{chen2023dargent,
author = {Chen, Zilin and Lafont, Ambroise and O'Connor, Liam and Keller, Gabriele and McLaughlin, Craig and Jackson, Vincent and Rizkallah, Christine},
title = {{Dargent: A Silver Bullet for Verified Data Layout Refinement}},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {POPL},
url = {https://doi.org/10.1145/3571240},
doi = {10.1145/3571240},
abstract = {Systems programmers need fine-grained control over the memory layout of data structures, both to produce performant code and to comply with well-defined interfaces imposed by existing code, standardised protocols or hardware. Code that manipulates these low-level representations in memory is hard to get right. Traditionally, this problem is addressed by the implementation of tedious marshalling code to convert between compiler-selected data representations and the desired compact data formats. Such marshalling code is error-prone and can lead to a significant runtime overhead due to excessive copying. While there are many languages and systems that address the correctness issue, by automating the generation and, in some cases, the verification of the marshalling code, the performance overhead introduced by the marshalling code remains. In particular for systems code, this overhead can be prohibitive. In this work, we address both the correctness and the performance problems. We present a data layout description language and data refinement framework, called Dargent, which allows programmers to declaratively specify how algebraic data types are laid out in memory. Our solution is applied to the Cogent language, but the general ideas behind our solution are applicable to other settings. The Dargent framework generates C code that manipulates data directly with the desired memory layout, while retaining the formal proof that this generated C code is correct with respect to the functional semantics. This added expressivity removes the need for implementing and verifying marshalling code, which eliminates copying, smoothens interoperability with surrounding systems, and increases the trustworthiness of the overall system.},
journal = {Proc. ACM Program. Lang.},
month = {jan},
articleno = {47},
numpages = {27},
keywords = {certifying compiler, data refinement, systems programming}
}

@misc{wadler1998expression,
  author = {Philip Wadler},
  title = {{The Expression Problem}},
  year={1998},
  month={November},
  day={12},
  url = {https://web.archive.org/web/20240510200911/http://homepages.inf.ed.ac.uk/wadler/papers/expression/expression.txt},
  note = {Accessed: {2024-08-11}}
}

@inproceedings{peytonjones1993imperative,
author = {{Peyton Jones}, Simon L. and Wadler, Philip},
title = {{Imperative Functional Programming}},
year = {1993},
isbn = {0897915607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/158511.158524},
doi = {10.1145/158511.158524},
abstract = {We present a new model, based on monads, for performing input/output in a non-strict, purely functional language. It is composable, extensible, efficient, requires no extensions to the type system, and extends smoothly to incorporate mixed-language working and in-place array updates.},
booktitle = {Proceedings of the 20th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {71–84},
numpages = {14},
location = {Charleston, South Carolina, USA},
series = {POPL '93}
}

@article{peytonjones2001tackling,
  title={{Tackling the Awkward Squad: Monadic Input/Output, Concurrency, Exceptions, and Foreign-language Calls in Haskell}},
  author={{Peyton Jones}, Simon},
  journal={NATO Science Series Sub Series III Computer and Systems Sciences},
  volume={180},
  pages={47--96},
  year={2001},
  url={https://web.archive.org/web/20221212192523/https://simon.peytonjones.org/assets/pdfs/tackling-awkward-squad.pdf}
}

@article{10.1145/942572.807045,
author = {Liskov, Barbara and Zilles, Stephen},
title = {{Programming with Abstract Data Types}},
year = {1974},
issue_date = {April 1974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/942572.807045},
doi = {10.1145/942572.807045},
abstract = {The motivation behind the work in very-high-level languages is to ease the programming task by providing the programmer with a language containing primitives or abstractions suitable to his problem area. The programmer is then able to spend his effort in the right place; he concentrates on solving his problem, and the resulting program will be more reliable as a result. Clearly, this is a worthwhile goal.Unfortunately, it is very difficult for a designer to select in advance all the abstractions which the users of his language might need. If a language is to be used at all, it is likely to be used to solve problems which its designer did not envision, and for which the abstractions embedded in the language are not sufficient.This paper presents an approach which allows the set of built-in abstractions to be augmented when the need for a new data abstraction is discovered. This approach to the handling of abstraction is an outgrowth of work on designing a language for structured programming. Relevant aspects of this language are described, and examples of the use and definitions of abstractions are given.},
journal = {SIGPLAN Not.},
month = {mar},
pages = {50–59},
numpages = {10}
}

@inproceedings{liskov1974abstract,
author = {Liskov, Barbara and Zilles, Stephen},
title = {{Programming with Abstract Data Types}},
year = {1974},
isbn = {9781450378840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800233.807045},
doi = {10.1145/800233.807045},
abstract = {The motivation behind the work in very-high-level languages is to ease the programming task by providing the programmer with a language containing primitives or abstractions suitable to his problem area. The programmer is then able to spend his effort in the right place; he concentrates on solving his problem, and the resulting program will be more reliable as a result. Clearly, this is a worthwhile goal.Unfortunately, it is very difficult for a designer to select in advance all the abstractions which the users of his language might need. If a language is to be used at all, it is likely to be used to solve problems which its designer did not envision, and for which the abstractions embedded in the language are not sufficient.This paper presents an approach which allows the set of built-in abstractions to be augmented when the need for a new data abstraction is discovered. This approach to the handling of abstraction is an outgrowth of work on designing a language for structured programming. Relevant aspects of this language are described, and examples of the use and definitions of abstractions are given.},
booktitle = {Proceedings of the ACM SIGPLAN Symposium on Very High Level Languages},
pages = {50–59},
numpages = {10},
location = {Santa Monica, California, USA}
}

@misc{brankov2014what,
  author = {Vladimir Brankov},
  title = {{What is Gained and Lost with 63-bit Integers?}},
  date = {2014-09-29},
  url = {https://web.archive.org/web/20240228085028/https://blog.janestreet.com/what-is-gained-and-lost-with-63-bit-integers/},
  note = {Accessed: {2024-08-12}}
}

@phdthesis{coquand1985,
  title = {{Une Théorie des Constructions}},
  author = {Coquand, Thierry},
  year = 1985,
  school = {Université Paris 7}
}
@phdthesis{werner1994,
  title = {{Une Théorie des Constructions Inductives}},
  author = {Werner, Benjamin},
  year = 1994,
  school = {Université Paris 7}
}

@misc{xkcd:haskell,
    author = {Randall Munroe},
    title = {{XKCD: Haskell}},
    url = {https://web.archive.org/web/20240727051624/https://xkcd.com/1312/},
    note = {Online; accessed 25-August-2024}
}

@inproceedings{jones1995functional,
  title={{Functional Programming with Overloading and Higher-Order Polymorphism}},
  author={Jones, Mark P},
  booktitle={Advanced Functional Programming: First International Spring School on Advanced Functional Programming Techniques B{\aa}stad, Sweden, May 24--30, 1995 Tutorial Text 1},
  pages={97--136},
  year={1995},
  organization={Springer},
  url={https://doi.org/10.1007/3-540-59451-5_4},
  doi={10.1007/3-540-59451-5_4}
}

@inproceedings{wadler1992essence,
author = {Wadler, Philip},
title = {{The Essence of Functional Programming}},
year = {1992},
isbn = {0897914538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/143165.143169},
doi = {10.1145/143165.143169},
abstract = {This paper explores the use monads to structure functional
programs. No prior knowledge of monads or category theory is
required.Monads increase the ease with which programs may be modified.
They can mimic the effect of impure features such as exceptions,
state, and continuations; and also provide effects not easily
achieved with such features. The types of a program reflect which
effects occur.The first section is an extended example of the use of monads. A
simple interpreter is modified to support various extra features:
error messages, state, output, and non-deterministic choice. The
second section describes the relation between monads and the
continuation-passing style. The third section sketches how monads
are used in a compiler for Haskell that is written in Haskell.},
booktitle = {Proceedings of the 19th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {1–14},
numpages = {14},
location = {Albuquerque, New Mexico, USA},
series = {POPL '92}
}

@article{swierstra2008data,
  title={{Data Types {\`a} la Carte}},
  author={Swierstra, Wouter},
  journal={{Journal of Functional Programming}},
  volume={18},
  number={4},
  pages={423--436},
  year={2008},
  publisher={Cambridge University Press}
}

@inproceedings{launcybury1994lazy,
author = {Launchbury, John and Peyton Jones, Simon L.},
title = {{Lazy Functional State Threads}},
year = {1994},
isbn = {089791662X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/178243.178246},
doi = {10.1145/178243.178246},
abstract = {Some algorithms make critical internal use of updatable state, even though their external specification is purely functional. Based on earlier work on monads, we present a way of securely encapsulating stateful computations that manipulate multiple, named, mutable objects, in the context of a non-strict, purely-functional language.The security of the encapsulation is assured by the type system, using parametricity. Intriguingly, this parametricity requires the provision of a (single) constant with a rank-2 polymorphic type.},
booktitle = {Proceedings of the ACM SIGPLAN 1994 Conference on Programming Language Design and Implementation},
pages = {24–35},
numpages = {12},
location = {Orlando, Florida, USA},
series = {PLDI '94}
}

@article{sakaguchi2020program,
title = {{Program Extraction for Mutable Arrays}},
journal = {Science of Computer Programming},
volume = {191},
pages = {102372},
year = {2020},
issn = {0167-6423},
url = {https://doi.org/10.1016/j.scico.2019.102372},
doi = {10.1016/j.scico.2019.102372},
author = {Kazuhiko Sakaguchi},
keywords = {Interactive theorem proving, Formally verified software, The Coq proof assistant, Program extraction, Program transformation and optimization},
abstract = {We present a lightweight method to represent, verify, and extract efficient programs involving mutable arrays in the Coq proof assistant. Our method mainly consists of a library for handling mutable arrays and an improved extraction plugin. Our library provides a monadic domain specific language for modeling computations involving mutable arrays, a simple reasoning method based on the Ssreflect extension and the Mathematical Components library, and an extraction method to efficient OCaml programs using in-place updates. Our extraction plugin improves the performance of our extracted programs, or more appropriately, through the application of simple program transformations for purely functional programs, it reduces both construction and destruction costs of inductive and coinductive objects and function call costs. As concrete applications for our method, we provide efficient implementations, correctness proofs, and benchmarks of the union–find data structure and the quicksort algorithm.}
}

@inproceedings{sansom1993generational,
author = {Sansom, Patrick M. and Peyton Jones, Simon L.},
title = {{Generational Garbage Collection for Haskell}},
year = {1993},
isbn = {089791595X},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/165180.165195},
doi = {10.1145/165180.165195},
booktitle = {Proceedings of the Conference on Functional Programming Languages and Computer Architecture},
pages = {106–116},
numpages = {11},
location = {Copenhagen, Denmark},
series = {FPCA '93}
}

@article{fenichel1969lisp,
author = {Fenichel, Robert R. and Yochelson, Jerome C.},
title = {{A LISP Garbage-Collector for Virtual-Memory Computer Systems}},
year = {1969},
issue_date = {Nov. 1969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {11},
issn = {0001-0782},
url = {https://doi.org/10.1145/363269.363280},
doi = {10.1145/363269.363280},
journal = {Commun. ACM},
month = {nov},
pages = {611–612},
numpages = {2},
keywords = {LISP: garbage-collector, list-processing, storage-allocation, virtual memory}
}

@inproceedings{denes2013towards,
  title={{Towards Primitive Data Types for Coq: 63-bits Integers and Persistent Arrays}},
  author={D{\'e}n{\`e}s, Maxime},
  booktitle={Coq-5, the Coq Workshop 2013},
  year={2013},
  url={https://web.archive.org/web/20240522104209/https://coq.inria.fr/files/coq5_submission_2.pdf}
}

@inproceedings{conchon2007persistent,
author = {Conchon, Sylvain and Filli\^{a}tre, Jean-Christophe},
title = {{A Persistent Union-Find Data Structure}},
year = {2007},
isbn = {9781595936769},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1292535.1292541},
doi = {10.1145/1292535.1292541},
abstract = {The problem of disjoint sets, also known as union-find, consists in maintaining a partition of a finite set within a data structure. This structure provides two operations: a function find returning the class of an element and a function union merging two classes. An optimal and imperative solution is known since 1975. However, the imperative nature of this data structure may be a drawback when it is used in a backtracking algorithm. This paper details the implementation of a persistent union-find data structure as efficient as its imperative counterpart. To achieve this result, our solution makes heavy use of imperative features and thus it is a significant example of a data structure whose side effects are safely hidden behind a persistent interface. To strengthen this last claim, we also detail a formalization using the Coq proof assistant which shows both the correctness of our solution and its observational persistence.},
booktitle = {Proceedings of the 2007 Workshop on Workshop on ML},
pages = {37–46},
numpages = {10},
keywords = {formal verification, persistence, union-find},
location = {Freiburg, Germany},
series = {ML '07}
}

@article{abel2017interactive,
  title={{Interactive Programming in Agda--Objects and Graphical User Interfaces}},
  author={Abel, Andreas and Adelsberger, Stephan and Setzer, Anton},
  journal={Journal of Functional Programming},
  volume={27},
  pages={e8},
  year={2017},
  publisher={Cambridge University Press},
  url={https://doi.org/10.1017/S0956796816000319},
  doi={10.1017/S0956796816000319}
}

@inproceedings{swierstra2007beauty,
author = {Swierstra, Wouter and Altenkirch, Thorsten},
title = {{Beauty in the Beast}},
year = {2007},
isbn = {9781595936745},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1291201.1291206},
doi = {10.1145/1291201.1291206},
abstract = {It can be very difficult to debug impure code, let alone prove its correctness. To address these problems, we provide a functional specification of three central components of Peyton Jones's awkward squad: teletype IO, mutable state, and concurrency. By constructing an internal model of such concepts within our programming language, we can test, debug, and reason about programs that perform IO as if they were pure. In particular, we demonstrate how our specifications may be used in tandem with QuickCheck to automatically test complex pointer algorithms and concurrent programs.},
booktitle = {Proceedings of the ACM SIGPLAN Workshop on Haskell Workshop},
pages = {25–36},
numpages = {12},
location = {Freiburg, Germany},
series = {Haskell '07}
}

@article{dybjer2000inductionrecursion,
  title={{A General Formulation of Simultaneous Inductive-Recursive Definitions in Type Theory}},
  volume={65},
  doi={10.2307/2586554},
  url = {https://doi.org/10.2307/2586554},
  number={2},
  journal={Journal of Symbolic Logic},
  author={Dybjer, Peter},
  year={2000},
  pages={525–549}
}